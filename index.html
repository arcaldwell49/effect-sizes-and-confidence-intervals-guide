<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matthew B. Jané">
<meta name="author" content="Qinyu Xiao">
<meta name="author" content="Siu Kit Yeung">
<meta name="author" content="Daniel J. Dunleavy">
<meta name="author" content="Lukas Röseler">
<meta name="author" content="Mahmoud Elsherif">
<meta name="author" content="Denis Cousineau">
<meta name="author" content="Aaron R. Caldwell">
<meta name="author" content="Blair T. Johnson">
<meta name="author" content="Gilad Feldman">
<meta name="keywords" content="effect size, confidence interval, collaboration, open science, open educational resource">

<title>Effect Sizes and Confidence Intervals Guide</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Effect Size Guide</h2>
   
  <ul>
  <li><a href="#guidelines-for-contribution" id="toc-guidelines-for-contribution" class="nav-link active" data-scroll-target="#guidelines-for-contribution">Guidelines for contribution</a>
  <ul class="collapse">
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  <li><a href="#credit-and-authorship" id="toc-credit-and-authorship" class="nav-link" data-scroll-target="#credit-and-authorship">Credit and authorship</a></li>
  </ul></li>
  <li><a href="#evaluating-and-interpreting-confidence-intervals" id="toc-evaluating-and-interpreting-confidence-intervals" class="nav-link" data-scroll-target="#evaluating-and-interpreting-confidence-intervals">Evaluating and Interpreting Confidence Intervals</a></li>
  <li><a href="#benchmarks" id="toc-benchmarks" class="nav-link" data-scroll-target="#benchmarks">Benchmarks</a></li>
  <li><a href="#reporting-effect-sizes" id="toc-reporting-effect-sizes" class="nav-link" data-scroll-target="#reporting-effect-sizes">Reporting Effect Sizes</a>
  <ul class="collapse">
  <li><a href="#transparency" id="toc-transparency" class="nav-link" data-scroll-target="#transparency">Transparency</a></li>
  <li><a href="#directionality" id="toc-directionality" class="nav-link" data-scroll-target="#directionality">Directionality</a></li>
  <li><a href="#precision" id="toc-precision" class="nav-link" data-scroll-target="#precision">Precision</a></li>
  </ul></li>
  <li><a href="#interpreting-confidence-intervals" id="toc-interpreting-confidence-intervals" class="nav-link" data-scroll-target="#interpreting-confidence-intervals">Interpreting Confidence Intervals</a></li>
  <li><a href="#reporting-confidence-intervals" id="toc-reporting-confidence-intervals" class="nav-link" data-scroll-target="#reporting-confidence-intervals">Reporting Confidence Intervals</a></li>
  <li><a href="#useful-r-packages" id="toc-useful-r-packages" class="nav-link" data-scroll-target="#useful-r-packages">Useful R Packages</a></li>
  <li><a href="#standardized-effect-sizes-for-mean-differences" id="toc-standardized-effect-sizes-for-mean-differences" class="nav-link" data-scroll-target="#standardized-effect-sizes-for-mean-differences">Standardized Effect Sizes for Mean Differences</a>
  <ul class="collapse">
  <li><a href="#single-group-designs" id="toc-single-group-designs" class="nav-link" data-scroll-target="#single-group-designs">Single Group Designs</a></li>
  <li><a href="#two-groups-design" id="toc-two-groups-design" class="nav-link" data-scroll-target="#two-groups-design">Two Groups Design</a></li>
  <li><a href="#repeated-measures-designs" id="toc-repeated-measures-designs" class="nav-link" data-scroll-target="#repeated-measures-designs">Repeated Measures Designs</a></li>
  <li><a href="#small-sample-bias-in-d-values" id="toc-small-sample-bias-in-d-values" class="nav-link" data-scroll-target="#small-sample-bias-in-d-values">Small Sample Bias in <span class="math inline">\(d\)</span> values</a></li>
  </ul></li>
  <li><a href="#correlation-between-two-continuous-variables" id="toc-correlation-between-two-continuous-variables" class="nav-link" data-scroll-target="#correlation-between-two-continuous-variables">Correlation between Two Continuous Variables</a></li>
  <li><a href="#effect-sizes-for-categorical-variables" id="toc-effect-sizes-for-categorical-variables" class="nav-link" data-scroll-target="#effect-sizes-for-categorical-variables">Effect Sizes for Categorical Variables</a>
  <ul class="collapse">
  <li><a href="#phi-coefficient-phi" id="toc-phi-coefficient-phi" class="nav-link" data-scroll-target="#phi-coefficient-phi">Phi Coefficient (<span class="math inline">\(\phi\)</span>)</a></li>
  <li><a href="#cramers-v" id="toc-cramers-v" class="nav-link" data-scroll-target="#cramers-v">Cramer’s <span class="math inline">\(V\)</span></a></li>
  <li><a href="#cohens-h" id="toc-cohens-h" class="nav-link" data-scroll-target="#cohens-h">Cohen’s <span class="math inline">\(h\)</span></a></li>
  <li><a href="#cohens-omega-omega" id="toc-cohens-omega-omega" class="nav-link" data-scroll-target="#cohens-omega-omega">Cohen’s omega (<span class="math inline">\(\omega\)</span>)</a></li>
  <li><a href="#ben-shachars-fei-פ" id="toc-ben-shachars-fei-פ" class="nav-link" data-scroll-target="#ben-shachars-fei-פ">Ben-Shachar’s Fei (פ)</a></li>
  <li><a href="#odds-ratio-or" id="toc-odds-ratio-or" class="nav-link" data-scroll-target="#odds-ratio-or">Odds Ratio (<span class="math inline">\(OR\)</span>)</a></li>
  <li><a href="#risk-difference-rd" id="toc-risk-difference-rd" class="nav-link" data-scroll-target="#risk-difference-rd">Risk Difference (<span class="math inline">\(RD\)</span>)</a></li>
  <li><a href="#relative-risk-rr" id="toc-relative-risk-rr" class="nav-link" data-scroll-target="#relative-risk-rr">Relative Risk (<span class="math inline">\(RR\)</span>)</a></li>
  </ul></li>
  <li><a href="#effect-sizes-for-anovas" id="toc-effect-sizes-for-anovas" class="nav-link" data-scroll-target="#effect-sizes-for-anovas">Effect Sizes for ANOVAs</a>
  <ul class="collapse">
  <li><a href="#eta-squared-eta2" id="toc-eta-squared-eta2" class="nav-link" data-scroll-target="#eta-squared-eta2">Eta-Squared (<span class="math inline">\(\eta^2\)</span>)</a></li>
  <li><a href="#partial-eta-squared-eta2_p" id="toc-partial-eta-squared-eta2_p" class="nav-link" data-scroll-target="#partial-eta-squared-eta2_p">Partial Eta-Squared (<span class="math inline">\(\eta^2_p\)</span>)</a></li>
  <li><a href="#generalized-eta-squared-eta2_g" id="toc-generalized-eta-squared-eta2_g" class="nav-link" data-scroll-target="#generalized-eta-squared-eta2_g">Generalized Eta-Squared (<span class="math inline">\(\eta^2_G\)</span>)</a></li>
  <li><a href="#omega-squared-corrections-omega2-omega2_p" id="toc-omega-squared-corrections-omega2-omega2_p" class="nav-link" data-scroll-target="#omega-squared-corrections-omega2-omega2_p">Omega squared corrections (<span class="math inline">\(\omega^2\)</span>, <span class="math inline">\(\omega^2_p\)</span>)</a></li>
  <li><a href="#cohens-f" id="toc-cohens-f" class="nav-link" data-scroll-target="#cohens-f">Cohen’s <span class="math inline">\(f\)</span></a></li>
  <li><a href="#reporting-anova-results" id="toc-reporting-anova-results" class="nav-link" data-scroll-target="#reporting-anova-results">Reporting ANOVA results</a></li>
  </ul></li>
  <li><a href="#converting-between-effect-sizes-and-test-statistics" id="toc-converting-between-effect-sizes-and-test-statistics" class="nav-link" data-scroll-target="#converting-between-effect-sizes-and-test-statistics">Converting between Effect Sizes and Test Statistics</a>
  <ul class="collapse">
  <li><a href="#converting-to-cohens-d" id="toc-converting-to-cohens-d" class="nav-link" data-scroll-target="#converting-to-cohens-d">Converting to Cohen’s <span class="math inline">\(d\)</span></a></li>
  <li><a href="#converting-to-pearson-correlation" id="toc-converting-to-pearson-correlation" class="nav-link" data-scroll-target="#converting-to-pearson-correlation">Converting to Pearson Correlation</a></li>
  <li><a href="#converting-to-odds-ratio" id="toc-converting-to-odds-ratio" class="nav-link" data-scroll-target="#converting-to-odds-ratio">Converting to Odds-Ratio</a></li>
  </ul></li>
  <li><a href="#non-parametric-tests" id="toc-non-parametric-tests" class="nav-link" data-scroll-target="#non-parametric-tests">Non-Parametric Tests</a>
  <ul class="collapse">
  <li><a href="#wilcoxon-mann-whitney-tests" id="toc-wilcoxon-mann-whitney-tests" class="nav-link" data-scroll-target="#wilcoxon-mann-whitney-tests">Wilcoxon-Mann-Whitney tests</a></li>
  <li><a href="#brunner-munzel-tests" id="toc-brunner-munzel-tests" class="nav-link" data-scroll-target="#brunner-munzel-tests">Brunner-Munzel Tests</a></li>
  </ul></li>
  <li><a href="#rank-based-effect-sizes" id="toc-rank-based-effect-sizes" class="nav-link" data-scroll-target="#rank-based-effect-sizes">Rank-Based Effect Sizes</a>
  <ul class="collapse">
  <li><a href="#rank-biserial-correlation" id="toc-rank-biserial-correlation" class="nav-link" data-scroll-target="#rank-biserial-correlation">Rank-Biserial Correlation</a></li>
  <li><a href="#concordance-probability" id="toc-concordance-probability" class="nav-link" data-scroll-target="#concordance-probability">Concordance Probability</a></li>
  <li><a href="#wilcoxin-mann-whitney-odds" id="toc-wilcoxin-mann-whitney-odds" class="nav-link" data-scroll-target="#wilcoxin-mann-whitney-odds">Wilcoxin-Mann-Whitney Odds</a></li>
  </ul></li>
  <li><a href="#artifacts-and-bias-in-effect-size-estimates" id="toc-artifacts-and-bias-in-effect-size-estimates" class="nav-link" data-scroll-target="#artifacts-and-bias-in-effect-size-estimates">Artifacts and Bias in Effect Size Estimates</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Effect Sizes and Confidence Intervals Guide</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://matthewbjane.com">Matthew B. Jané</a> <a href="https://orcid.org/0000-0002-3121-7769" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Connecticut
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Qinyu Xiao <a href="https://orcid.org/0000-0002-9824-9247" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Vienna
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Siu Kit Yeung <a href="https://orcid.org/0000-0002-5835-0981" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Chinese University of Hong Kong
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Daniel J. Dunleavy <a href="https://orcid.org/0000-0002-3597-7714" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Florida State
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Lukas Röseler <a href="https://orcid.org/0000-0002-6446-1901" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Bamberg
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Mahmoud Elsherif <a href="https://orcid.org/0000-0002-0540-3998" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Birmingham
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Denis Cousineau <a href="https://orcid.org/0000-0001-5908-0402" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Université d’Ottawa
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Aaron R. Caldwell <a href="https://orcid.org/0000-0002-4541-6283" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Arkansas for Medical Sciences
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Blair T. Johnson </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Connecticut
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Gilad Feldman <a href="https://orcid.org/0000-0003-2812-6599" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Hong Kong
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    This effect sizes and confidence intervals collaborative guide aims to provide students and early-career researchers with hands-on, step-by-step instructions for calculating effect sizes and confidence intervals for common statistical tests used in psychology, social sciences and behavioral sciences, particularly when original data are not available and when reported information is incomplete. It also introduces general background information on effect sizes and confidence intervals, as well as useful R packages for their calculation. Many of the methods and procedures described in this Guide are based on R or R-based Shiny Apps developed by the science community. We were motivated to focus on R as we aim to maximize the reproducibility of our research outcomes and encourage the most reproducible study planning and data analysis workflow, though we also document other methods whenever possible for the reference of our readers. We regularly update this open educational resource, as packages are updated frequently and new packages are developed from time to time in this rapidly changing Open Scholarship era.
  </div>
</div>

</header>

<p><em>Note.</em> This is a constantly updated collaborative guide on effect sizes and confidence intervals. The most up-to-date version of this guide is hosted as a Google Doc at this link: <a href="https://mgto.org/effectsizeguide" class="uri">https://mgto.org/effectsizeguide</a>. A similar guide on power analysis can be found at: <a href="https://mgto.org/poweranalysisguide" class="uri">https://mgto.org/poweranalysisguide</a>. This guide is shared under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> license.</p>
<section id="guidelines-for-contribution" class="level2">
<h2 class="anchored" data-anchor-id="guidelines-for-contribution">Guidelines for contribution</h2>
<p>All are encouraged to contribute to this Guide. Please note that this Guide is in continuous development such that it will remain a work in progress for an indefinite period of time. This is intended because we hope the Guide to always reflect the state of the art on the topics of effect sizes and confidence intervals.</p>
<section id="notes" class="level3">
<h3 class="anchored" data-anchor-id="notes">Notes</h3>
<ul>
<li><p>Please use the headings and style as set forth in this document. You can use keyboard shortcuts such as Ctrl + Alt + 1/2/3. The normal text is in Times New Roman font, font size 11. The codes are formatted using the Code Blocks add-on of Google Docs, github theme, font size 8.</p></li>
<li><p>Use the Suggesting mode rather than the Editing mode. Suggesting is now the default mode for this document. Therefore, please do not hesitate to correct mistakes or modify the contents directly.</p></li>
<li><p>Add a comment to the document if you find anything missing or improper, or if you feel that things are better organized in a different way. We appreciate your suggestions. If you have any questions, please also add a comment. We will reply and seek to clarify in the document body.</p></li>
<li><p>Please make proper citations (in APA 7th format) and provide relevant links when you refer to any source that is not your own.</p></li>
</ul>
</section>
<section id="credit-and-authorship" class="level3">
<h3 class="anchored" data-anchor-id="credit-and-authorship">Credit and authorship</h3>
<p>If you believe you have made sufficient contribution that qualifies you as an author, and you would like to be listed as an author of this Guide, please do not hesitate and list your name and contact information below. The administrators (Q.-Y. X., S. K. Y., and G. F.) of this Guide will verify your contribution and add you to the author list. We welcome comments from any person, regardless of whether they want to be an author. You are also welcome to request content to be added to this Guide (please see the Things to add to the guide section in the end).</p>
<p>The authorship order is such that Q.-Y. X. and S. K. Y. will be the first two authors and G. F. will be the last and the corresponding author. All other contributors will be listed alphabetically in the middle and are all considered joint third authors. Contributors are by default given investigation, writing - original draft, and writing - review &amp; editing CRediT authorship roles. It is possible to take on more roles if contributors prefer. Any change in this authorship order rule will have to be approved by all who are already listed as an author.</p>
</section>
</section>
<section id="evaluating-and-interpreting-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-and-interpreting-confidence-intervals">Evaluating and Interpreting Confidence Intervals</h2>
<p>Effect sizes quantify the magnitude of effects (i.e., strength of a relationship, size of a difference), which are the outcomes of our empirical research. Effect sizes are by no means a new concept. However, reporting them remained largely optional for many years, and only until recently does it become a community standard: scientists now see reporting effect sizes (in addition to the traditional statistical significance) as a must and journals also start to require such reporting. Notably, in 2001 and 2010, The Publication Manual of the American Psychological Association 5th and 6th editions emphasized that it is “almost always necessary”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to report effect sizes <span class="citation" data-cites="association2010 fritz2012">(<a href="#ref-association2010" role="doc-biblioref">Association 2010, 34</a>; see <a href="#ref-fritz2012" role="doc-biblioref">Fritz, Morris, and Richler 2012</a>, which provides a comprehensive summary on history and importance of effect size reporting)</span>.</p>
<p>Effects sizes can be grouped in broad categories as (1) raw effect sizes, and (2) standardized effect sizes. The raw effect sizes are summary of the results that are expressed in the same units as the raw data. For example, when kilograms are measured, a raw effect size reports a measure in kilogram. Consider the effect of a diet on a treatment group; a control group receives no diet. The change in weight can be expressed as the mean difference between the group. This measure is also in kg and so is a raw effect size. Standardized effect sizes are expressed on a standardized scale which has no longer any unit but which have a universal interpretation. A z score is an example of a standardized measure. This document is concerned exclusively on standardized effect sizes.</p>
</section>
<section id="benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="benchmarks">Benchmarks</h2>
<p>What makes an effect size “large” or “small” is completely dependent on the context of the study in question. However, it can be useful to have some loose criterion in order to guide researchers in effectively communicating effect size estimates. Jacob Cohen <span class="citation" data-cites="cohen1988">(<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span>, the pioneer of estimation statistics, suggested many conventional benchmarks (i.e., how we refer to an effect size other than using a number) that we currently use. However, <span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span> noted that labels such as “small”, “medium”, and “large” are relative, and in referring to the size of an effect, the discipline, the context of research, as well as the research method and goals, should take precedence over benchmarks any time it’s possible. There are general differences in effect sizes across different disciplines, and within each discipline, effect sizes differ depending on study designs and research methods <span class="citation" data-cites="schäfer2019">(<a href="#ref-schäfer2019" role="doc-biblioref">Schäfer and Schwarz 2019</a>)</span> and goals; as <span class="citation" data-cites="glass1981a">Glass, McGaw, and Smith (<a href="#ref-glass1981a" role="doc-biblioref">1981</a>)</span> explains:</p>
<blockquote class="blockquote">
<p>Depending on what benefits can be achieved at what cost, an effect size of 2.0 might be “poor” and one of .1 might be “good.”</p>
</blockquote>
<p>Therefore, it is crucial to recognize that benchmarks are only general guidelines, and importantly, out of context. They also are tend to attract controversy <span class="citation" data-cites="glass1981a kelley2012 harrell2020">(<a href="#ref-glass1981a" role="doc-biblioref">Glass, McGaw, and Smith 1981</a>; <a href="#ref-kelley2012" role="doc-biblioref">Kelley and Preacher 2012</a>; <a href="#ref-harrell2020" role="doc-biblioref">Harrell 2020</a>)</span>. Note that empirical benchmarks have been suggested by researchers. For social psychology, these alternative benchmarks obtained through meta-analyzing the literature (for example, <a href="https://doi.org/10.1037/1089-2680.7.4.331">this</a> and <a href="https://doi.org/10.1016/j.paid.2016.06.069">this</a>; see <a href="https://twitter.com/cjsotomatic/status/1144701540839698432">this Twitter thread</a> for a summary) are typically smaller than what Cohen put forward. Please refer to the table below:</p>
<table class="table">
<thead>
<tr class="header">
<th>Effect Size</th>
<th>Reference</th>
<th style="text-align: center;">Small</th>
<th style="text-align: center;">Medium</th>
<th style="text-align: center;">Large</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Mean Differences</em></td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Cohen’s <span class="math inline">\(d\)</span> or Hedges’ <span class="math inline">\(g\)</span></td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></td>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.80</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.60</td>
</tr>
<tr class="even">
<td></td>
<td><span class="citation" data-cites="lovakov2021">Lovakov and Agadullina (<a href="#ref-lovakov2021" role="doc-biblioref">2021</a>)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.65</td>
</tr>
<tr class="odd">
<td><em>Correlational</em></td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Correlation Coefficient (<span class="math inline">\(r\)</span>)</td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">.10</td>
<td style="text-align: center;">.30</td>
<td style="text-align: center;">.50</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="citation" data-cites="richard2003">Richard, Bond Jr., and Stokes-Zoota (<a href="#ref-richard2003" role="doc-biblioref">2003</a>)</span><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></td>
<td style="text-align: center;">.10</td>
<td style="text-align: center;">.20</td>
<td style="text-align: center;">.30</td>
</tr>
<tr class="even">
<td></td>
<td><span class="citation" data-cites="lovakov2021">Lovakov and Agadullina (<a href="#ref-lovakov2021" role="doc-biblioref">2021</a>)</span></td>
<td style="text-align: center;">.12</td>
<td style="text-align: center;">.24</td>
<td style="text-align: center;">.41</td>
</tr>
<tr class="odd">
<td></td>
<td><span class="citation" data-cites="paterson2016">Paterson et al. (<a href="#ref-paterson2016" role="doc-biblioref">2016</a>)</span></td>
<td style="text-align: center;">.12</td>
<td style="text-align: center;">.20</td>
<td style="text-align: center;">.31</td>
</tr>
<tr class="even">
<td></td>
<td><span class="citation" data-cites="bosco2015">Bosco et al. (<a href="#ref-bosco2015" role="doc-biblioref">2015</a>)</span></td>
<td style="text-align: center;">.09</td>
<td style="text-align: center;">.18</td>
<td style="text-align: center;">.26</td>
</tr>
<tr class="odd">
<td>Cohen’s <span class="math inline">\(f^2\)</span></td>
<td></td>
<td style="text-align: center;">.02</td>
<td style="text-align: center;">.25</td>
<td style="text-align: center;">.40</td>
</tr>
<tr class="even">
<td>eta-squared (<span class="math inline">\(\eta^2\)</span>)</td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">.01</td>
<td style="text-align: center;">.06</td>
<td style="text-align: center;">.14</td>
</tr>
<tr class="odd">
<td>Cohen’s <span class="math inline">\(q\)</span></td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Cohen’s f</td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">.10</td>
<td style="text-align: center;">.25</td>
<td style="text-align: center;">.40</td>
</tr>
<tr class="odd">
<td><em>Categorical</em></td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Cohen’s omega</td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.50</td>
</tr>
<tr class="odd">
<td>Phi</td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">.10</td>
<td style="text-align: center;">.30</td>
<td style="text-align: center;">.50</td>
</tr>
<tr class="even">
<td>Cramer’s V</td>
<td></td>
<td style="text-align: center;"><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>Odds ratio</td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Relative risk</td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>Risk difference</td>
<td></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>Cohen’s <span class="math inline">\(h\)</span></td>
<td><span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span></td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.8</td>
</tr>
</tbody>
</table>
<p>It should be noted that small/medium/large effects do not necessarily mean that they have small/medium/large practical implications <span class="citation" data-cites="coe2012 pogrow2019">(for details see, <a href="#ref-coe2012" role="doc-biblioref">Coe 2012</a>; <a href="#ref-pogrow2019" role="doc-biblioref">Pogrow 2019</a>)</span>. These benchmarks are more relevant for guiding our expectations. Whether they have practical importance depends on contexts. To assess practical importance, it will always be desirable for standardized effect sizes to be translated to increase/decrease in raw units (or any meaningful units) or a Binomial Effect Size Display (roughly, differences in proportions such as success rate before and after intervention).</p>
<p><strong>Please also note that only zero means no effect</strong>. An effect of the size .01 is an effect, but a very small <span class="citation" data-cites="sawilowsky2009">(<a href="#ref-sawilowsky2009" role="doc-biblioref">Sawilowsky 2009</a>)</span>, and likely unimportant, one. It makes sense to say that “we failed to find evidence for rejecting the null hypothesis,” or “we found evidence for only a small/little/weak-to-no effect” or “we did not find a meaningful effect”. <strong>It does not make sense to say, “we found no effect.”</strong> Purely by the random nature of our universe, it is hard to imagine that we can obtain a sharp zero-effect result. This is also related to the crud factor, which refers to the idea that “everything correlates with everything else” <span class="citation" data-cites="orben2020 meehl1984">(<a href="#ref-orben2020" role="doc-biblioref">Orben and Lakens 2020, 1</a>; <a href="#ref-meehl1984" role="doc-biblioref">Meehl 1984</a>)</span>, but the practical implication of very weak/small correlations between some variables may be limited, and whether the effect is reliably detected depends on statistical power.</p>
</section>
<section id="reporting-effect-sizes" class="level2">
<h2 class="anchored" data-anchor-id="reporting-effect-sizes">Reporting Effect Sizes</h2>
<section id="transparency" class="level3">
<h3 class="anchored" data-anchor-id="transparency">Transparency</h3>
<p>When reporting effect sizes and their calculations, you should prioritize transparency and reproducibility. No matter what tool you used to calculate your effect size (R is the most recommended tool here), you must make sure that others can easily follow your procedures and obtain the same results. This means that if you use online calculators (which is discouraged) or standalone programs (JAMOVI is most recommended; you can also use JASP, which however does not allow access to syntax at this moment), you should include screenshots that capture the input and output, with clear explanations. If you use R, Python or other programming languages, you should copy-and-paste your codes into your supplementary document (or submit your scripts to open online repositories), ideally with annotations and comments explaining the codes. inputs and outputs.</p>
</section>
<section id="directionality" class="level3">
<h3 class="anchored" data-anchor-id="directionality">Directionality</h3>
<p>Some effect sizes are directional (e.g., Cohen’s <span class="math inline">\(d\)</span>), which means that they can be positive or negative. Their signs carry important information, and therefore cannot be omitted. When you report these effect sizes, make it clear what is compared to what (i.e., the direction of comparison). Better still, make sure your comparison is inline with the theory. For instance, a theory predicts that your group X should score higher on an item than your Group Y,<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> you should hypothesize accordingly that Group X will have a higher mean than Group Y on the item, and subtract mean(Y) from mean(X) (rather than the other way around) to obtain the mean difference. You should then expect your <span class="math inline">\(t\)</span> statistic to be positive, and your <span class="math inline">\(d\)</span> value as well. In other words, avoid reporting anything like <span class="math inline">\(t\)</span> = -5.14, <span class="math inline">\(d\)</span> = 0.36, where the signs of the statistics do not match.</p>
</section>
<section id="precision" class="level3">
<h3 class="anchored" data-anchor-id="precision">Precision</h3>
<p>Effect sizes may be very precisely estimated from the available data, the used methodology, and how the population was sampled. It might also be estimated with little confidence on the resulting number. This may be the case for example when the sample is very small, when the population displays a lot of variability, when a between-group design is used instead of a paired-sample design, and finally, when clustered sampling is used instead of randomized sampling. Precision can be estimated using various tools, but probably the most commonly used one is the Confidence intervals. This interval has a confidence level, frequently 95%.</p>
</section>
</section>
<section id="interpreting-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-confidence-intervals">Interpreting Confidence Intervals</h2>
<p>What is the correct interpretation of a confidence interval? Imagine you conducted a study where you compared two groups. You obtained a Cohen’s <span class="math inline">\(d\)</span> = 0.3, 95% CI [0.2, 0.4]. How do you interpret this confidence interval?</p>
<p>Confidence intervals are yielded by a certain procedure, such that when the procedure is repeatedly applied to a series of hypothetical datasets drawn from the studied population/populations, it yields intervals that contain the true parameter value (in our example, it means the true difference between the two groups) in 95% of the cases.</p>
<p>In colloquial terms, if we conduct this research over and over (repeating the same sampling procedure, administering the same experimental manipulation, conducting the same statistical analysis, etc.), because of sampling variability (our samples are slightly different at each time), we will get different Cohen’s <span class="math inline">\(d\)</span> values. For each of these <span class="math inline">\(d\)</span> values, we calculate a 95% interval. Then, among all these many intervals, we expect that 95% of them will contain the true <span class="math inline">\(d\)</span>, which we never know exactly.</p>
<p>There is also a common criticism levied against the confidence interval interpretation: “There is a 95% probability that the true parameter exists within the 95% confidence interval”. However this criticism is unwarranted in the specific case of a single observed confidence interval, that is, as long as there is a single realized confidence interval sampled from the population, this interpretation is fine <span class="citation" data-cites="vos2022">(<a href="#ref-vos2022" role="doc-biblioref">Vos and Holbert 2022</a>)</span>. It is important to note however, this interpretation is incorrect when there are multiple realized confidence intervals randomly sampled from the same population. The criticized interpretation also tends to be more practical than the interpretation using repeated sampling, the following example described by <span class="citation" data-cites="vos2022">Vos and Holbert (<a href="#ref-vos2022" role="doc-biblioref">2022</a>)</span> illustrates this,</p>
<blockquote class="blockquote">
<p>The distinction between these interpretations can be understood with the simple example of the probability of rolling a ‘6’ with a fair die. The probability is 1/6 because if you roll the die repeatedly the proportion of times that the face with ‘6’ comes up will be come very close to 1/6. Or, the probability is 1/6 because it is equivalent to a random selection from an urn where exactly one of 6 balls is labelled with ‘6’. The distinction in this simple example is less useful since repeatedly rolling a die is less problematic than repeatedly conducting the same randomized trial.</p>
</blockquote>
<p>For further reading on confidence interpretations, see <span class="citation" data-cites="hoekstra2014">Hoekstra et al. (<a href="#ref-hoekstra2014" role="doc-biblioref">2014</a>)</span> and <span class="citation" data-cites="morey2016">Morey et al. (<a href="#ref-morey2016" role="doc-biblioref">2016</a>)</span>.</p>
</section>
<section id="reporting-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="reporting-confidence-intervals">Reporting Confidence Intervals</h2>
<p>Confidence intervals must be calculated and reported for every effect size that you obtained and mentioned in your manuscript. If you are doing a replication and your target article/study did not report CIs for its effect sizes, you should calculate CIs and report them.</p>
<p>Normally, we calculate 95% confidence intervals (i.e., 95% of such intervals are expected to contain the true parameter value if we conduct an infinite number of identical studies). Nonetheless, for some effect sizes (e.g., eta-squared, partial eta-squared, R-squared), we calculate 90% confidence intervals. This is because η² is squared and always positive, and F-tests are one-sided. Reporting 95% CI for eta squared may result in situations in which the CI includes zero but the p-value falls below .05, whereas reporting 90% CI prevents such a problem. For further information regarding this issue, read Daniel Lakens blog on confidence intervals and <span class="citation" data-cites="steiger2004">Steiger (<a href="#ref-steiger2004" role="doc-biblioref">2004</a>)</span>.</p>
<p>Confidence intervals should be reported immediately after an effect size, e.g., Cohen’s d = 0.40, 95% CI [0.20, 0.60]. After the first time reporting them in a manuscript, every subsequent CI can be simply denoted by brackets without the “95% CI” preceding it.</p>
<p>Unless you are measuring something that is meaningful in real life (e.g., income, years of experience, amount that a person is willing to donate), please make sure that the CI you calculated is a CI of the effect size, not of other statistics, such as the test statistics or mean difference in raw units.</p>
<p>If you see one of the following:</p>
<ol type="1">
<li><p>Your effect size estimate does not fall in your confidence interval: you certainly have an issue.</p></li>
<li><p>One of your CI bound is “infinite”</p></li>
<li><p>Your effect size estimate is not included within your CI (for comparison between two groups): You have an issue, check carefully. For means and for difference in means, the estimate should be precisely the midpoint of your CI; for other statistics (e.g., correlation, proportion, frequency, standard deviation), one arm might be longer than the other so the estimate may not be the midpoint.</p></li>
</ol>
<p>For further reading related to the calculaton and reporting of effect sizes and confidence intervals, see <span class="citation" data-cites="steiger2004">Steiger (<a href="#ref-steiger2004" role="doc-biblioref">2004</a>)</span> and <span class="citation" data-cites="lakens2014">Lakens (<a href="#ref-lakens2014" role="doc-biblioref">2014</a>)</span>.</p>
</section>
<section id="useful-r-packages" class="level2">
<h2 class="anchored" data-anchor-id="useful-r-packages">Useful R Packages</h2>
<p>The following R packages are handy for effect size and CI calculations, conversions among different effect sizes, and conversion of test statistics to effect sizes. If you use one of the packages below, please make sure you cite them to give the authors their due credit! To obtain citations for packages, you can use the <code>citation()</code> function and input the name of the package as a string.</p>
<ul>
<li><p><code>MOTE</code> <span class="citation" data-cites="MOTE">(<a href="#ref-MOTE" role="doc-biblioref">Buchanan et al. 2019</a>)</span>: This is a highly recommended package for calculating effect sizes, which is capable of handling a wide variety of effect sizes in the difference family (the d family) and variance-overlap family (r, eta, omega, epsilon). The functions also provide non-central confidence intervals for each effect size and output in APA style in LaTeX. <code>MOTE</code> has an online shiny application (<a href="https://doomlab.shinyapps.io/mote/">doomlab.shinyapps.io/mote/</a>). The CRAN project can be found here: <a href="https://cran.r-project.org/package=MOTE">cran.r-project.org/package=MOTE</a>.</p></li>
<li><p><code>effectsize</code> <span class="citation" data-cites="effectsize">(<a href="#ref-effectsize" role="doc-biblioref">Ben-Shachar, Lüdecke, and Makowski 2020</a>)</span>: This package is particularly useful in data analysis. A major advantage of this package is that it takes in many different model objects and directly outputs effect sizes and CIs. It also does some conversion. The CRAN project can be found here: <a href="https://cran.r-project.org/package=effectsize">cran.r-project.org/package=effectsize</a>.</p></li>
<li><p><code>MBESS</code> <span class="citation" data-cites="MBESS">(<a href="#ref-MBESS" role="doc-biblioref">Kelley 2022</a>)</span>: One of the most comprehensive and useful packages for effect size and confidence interval calculations. It provides functions that can calculate ESs and CIs from test statistics and the p-value. The CRAN project can be found here: <a href="https://cran.r-project.org/package=MBESS">cran.r-project.org/package=MBESS</a>.</p></li>
<li><p><code>metafor</code> <span class="citation" data-cites="metafor">(<a href="#ref-metafor" role="doc-biblioref">Viechtbauer 2010</a>)</span>: Probably the most comprehensive meta-analysis package currently available. Includes the function, <code>escalc()</code>, that calculates various types of effect sizes from test-statistics, summary statistics, and more. The CRAN project can be found here: <a href="https://cran.r-project.org/package=metafor">cran.r-project.org/package=metafor</a>.</p></li>
<li><p><code>psych</code> <span class="citation" data-cites="psych">(<a href="#ref-psych" role="doc-biblioref">William Revelle 2023</a>)</span>: One of the most comprehensive and general packages for common statistical procedures in psychology research. It also includes some effect size and CI calculation functions (e.g., <code>cohen.d()</code>). The CRAN project can be found here: <a href="https://cran.r-project.org/package=psych">cran.r-project.org/package=psych</a>.</p></li>
<li><p><code>esc</code> <span class="citation" data-cites="esc">(<a href="#ref-esc" role="doc-biblioref">Lüdecke 2019</a>)</span>: This package can help convert among different effect sizes (pp.&nbsp;4-12 in the reference manual). It’s also helpful when only incomplete information (e.g., only descriptives, or only p-values) have been provided in the paper, and we want to calculate effect sizes from them. Another package that provides similar conversion functions is the <code>compute.es</code> package. The CRAN project can be found here: <a href="https://cran.r-project.org/package=esc">cran.r-project.org/package=esc</a>.</p></li>
<li><p><code>psychmeta</code> <span class="citation" data-cites="psychmeta">(<a href="#ref-psychmeta" role="doc-biblioref">Dahlke and Wiernik 2019</a>)</span>: This package is mainly used for psychometric meta-analyses. It has a function for converting different effect sizes/test statistics (convert_es, p.&nbsp;38 in the reference manual), including <span class="math inline">\(r\)</span>, <span class="math inline">\(d\)</span>, <span class="math inline">\(t\)</span>-statistic (and its p-value), <span class="math inline">\(F\)</span> (and its p-value in two-group one-way ANOVA), chi-squared (one degree of freedom), etc., to <span class="math inline">\(r\)</span>, <span class="math inline">\(d\)</span> and the common language effect sizes (CLES, A, AUC). The CRAN project can be found here <a href="https://cran.r-project.org/package=psychmeta">cran.r-project.org/package=psychmeta</a>.</p></li>
<li><p><code>effsize</code> <span class="citation" data-cites="effsize">(<a href="#ref-effsize" role="doc-biblioref">Torchiano 2020</a>)</span>: This is a relatively lightweight package that handles d, g, Cliff delta, and Vargha-Delaney A). The CRAN project can be found here: <a href="https://cran.r-project.org/package=effsize">cran.r-project.org/package=effsize</a>.</p></li>
<li><p><code>MAd</code> <span class="citation" data-cites="MAd">(<a href="#ref-MAd" role="doc-biblioref">W. T. Hoyt 2014</a>)</span>: This package is a collection of functions for conducting a meta-analysis with mean differences data. It also provides conversion functions. The CRAN project can be found here: <a href="https://cran.r-project.org/package=MAd">cran.r-project.org/package=MAd</a>.</p></li>
<li><p><code>TOSTER</code> <span class="citation" data-cites="TOSTER">(<a href="#ref-TOSTER" role="doc-biblioref">Daniel, Lakens, and aut 2017</a>)</span>: This package is used for equivalence testing. It contains many functions to test for differences in effect sizes along with other useful functions for effect size comparisons. The CRAN project can be found here: <a href="https://cran.r-project.org/package=TOSTER">cran.r-project.org/package=TOSTER</a>.</p></li>
<li><p><code>DeclareDesign</code> <span class="citation" data-cites="DeclareDesign">(<a href="#ref-DeclareDesign" role="doc-biblioref">Blair et al. 2019</a>)</span>: This simulation framework can be used to assess whether procedures for calculating confidence intervals are valid and can be used for arbitrary designs. The <code>diagnose_design()</code> function calculates coverage for designs with estimation strategies that produce confidence intervals. The CRAN project can be found here: <a href="https://cran.r-project.org/package=DeclareDesign">cran.r-project.org/package=DeclareDesign</a>.</p></li>
</ul>
</section>
<section id="standardized-effect-sizes-for-mean-differences" class="level2">
<h2 class="anchored" data-anchor-id="standardized-effect-sizes-for-mean-differences">Standardized Effect Sizes for Mean Differences</h2>
<p>T-tests are the most commonly used statistical tests for examining differences between group means, or examining a group mean against a constant. Calculating effect sizes for t-tests is fairly straightforward. Nonetheless, there are cases where crucial figures for the calculation are missing (which happens quite often in older articles), and therefore we document methods that make use of partial information (e.g., only the M and the SD, or only the t-statistic and df) for the calculation. There are multiple types of effect sizes used to calculate standardized mean differences (i.e., Cohen’s <span class="math inline">\(d\)</span>), yet researchers very often do not identify which type of <span class="math inline">\(d\)</span> value they are reporting <span class="citation" data-cites="lakens2013">(see <a href="#ref-lakens2013" role="doc-biblioref">Lakens 2013</a>)</span>. Here we document the equations and code necessary for calculating each type of <span class="math inline">\(d\)</span> value compiled across multiple sources <span class="citation" data-cites="becker1988 cohen1988 lakens2013 caldwell glass1981a">(<a href="#ref-becker1988" role="doc-biblioref">Becker 1988</a>; <a href="#ref-cohen1988" role="doc-biblioref">Cohen 1988</a>; <a href="#ref-lakens2013" role="doc-biblioref">Lakens 2013</a>; <a href="#ref-caldwell" role="doc-biblioref">Caldwell, n.d.</a>; <a href="#ref-glass1981a" role="doc-biblioref">Glass, McGaw, and Smith 1981</a>)</span>. A <span class="math inline">\(d\)</span> value calculated from a sample will also contain sampling error, therefore we will also show the equations to calculate the standard error. The standard allows us to then calculate the confidence interval. For each formulation in the sections below, the confidence interval will be able to be calculated in the same way, that is,</p>
<p><span id="eq-ci-low"><span class="math display">\[
\text{Lower Bound} = d - 1.96\times SE
\tag{1}\]</span></span></p>
<p><span id="eq-ci-high"><span class="math display">\[
\text{Upper Bound} = d + 1.96\times SE
\tag{2}\]</span></span></p>
<p>Lastly, we will supply example R code so you can apply to your own data.</p>
<section id="single-group-designs" class="level3">
<h3 class="anchored" data-anchor-id="single-group-designs">Single Group Designs</h3>
<p>For a single group design, we have one group and we want to compare the mean of that group to some constant, <span class="math inline">\(C\)</span> (i.e., a target value). The standardized mean difference for a single group can be calculated by,</p>
<p><span class="math display">\[
d_s = \frac{M-C}{S_1}
\]</span><br>
A positive <span class="math inline">\(d_s\)</span> value would indicate that the mean of group 1 is larger than the target value, <span class="math inline">\(C\)</span>. This formulation assumes that the sample is drawn from a normal distribution. The standardizer (i.e., the denominator) is the sample standard deviation. The corresponding standard error for <span class="math inline">\(d_s\)</span> is,</p>
<p><span class="math display">\[
SE_{d_s} = \sqrt{\frac{1}{n}+\frac{d_1^2}{2n}}.
\]</span></p>
<p>In R, we can use the <code>d.single.t</code> function from the <code>MOTE</code> package to calculate the single group standardized mean difference.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install packages if not already installed:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages('MOTE')</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d for one group</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample Mean = 30.4, SD = 22.53, N = 96</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Target Value, C = 15</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MOTE)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">d.single.t</span>(</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">m =</span> <span class="fl">30.4</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">u =</span> <span class="dv">15</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="fl">22.53</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">96</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.684 0.460 0.904</code></pre>
</div>
</div>
<p>As you can see, the output shows that the effect size is <span class="math inline">\(d_s\)</span> = 0.68, 95% CI [0.46, 0.90]. Note the <code>apa</code> function in <code>MOTE</code> takes a value and returns an APA formatted effect size value (i.e., leading zero and three decimal places).</p>
</section>
<section id="two-groups-design" class="level3">
<h3 class="anchored" data-anchor-id="two-groups-design">Two Groups Design</h3>
<section id="standardize-by-pooled-standard-deviation-d_p" class="level4">
<h4 class="anchored" data-anchor-id="standardize-by-pooled-standard-deviation-d_p">Standardize by Pooled Standard Deviation (<span class="math inline">\(d_p\)</span>)</h4>
<p>For a two group design (i.e., between-groups design), we want to compare the means of two groups (group 1 and group 2). The standardized mean difference between two groups can be calculated by,</p>
<p><span class="math display">\[
d_p = \frac{M_1-M_2}{S_p}.
\]</span></p>
<p>A positive <span class="math inline">\(d_p\)</span> value would indicate that the mean of group 1 is larger than the mean of group 2. Dividing the mean difference by the pooled standard deviation, <span class="math inline">\(S_p\)</span>, is the classic formulation of Cohen’s <span class="math inline">\(d\)</span>. The pooled standard deviation, <span class="math inline">\(S_p\)</span>, can be calculated as the square root of the average variance (weighted by the degrees of freedom, <span class="math inline">\(df=n-1\)</span>) of group 1 and group 2:</p>
<p><span class="math display">\[
S_p = \sqrt{\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}}
\]</span></p>
<p>Note that the term <em>variance</em> refers to the square of the standard deviation (<span class="math inline">\(S^2\)</span>). Cohen’s <span class="math inline">\(d_p\)</span> has is related to the t-statistic from an independent samples t-test. In fact, we can calculate the <span class="math inline">\(d_p\)</span> value from the <span class="math inline">\(t\)</span>-statistic with the following formula:</p>
<p><span class="math display">\[
d = t\sqrt{\frac{2(n_1+n_2)}{n_1 n_2(n_1+n_2-2)}}.
\]</span></p>
<p>The corresponding standard error of <span class="math inline">\(d_p\)</span> is,</p>
<p><span class="math display">\[
SE_{d_p} = \sqrt{\frac{n_1+n_2}{n_1 n_2}+\frac{d_p^2}{2(n_1+n_2)}}.
\]</span></p>
<p>In R, we can use the <code>d.ind.t</code> function from the <code>MOTE</code> package to calculate the two group standardized mean difference. Since we have already loaded in the <code>MOTE</code> package, we do not need to again.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d for two independent groups</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># given means and SDs</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 1 Mean = 30.4, SD = 22.53, N = 96</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 2 Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">d.ind.t</span>(</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">m1 =</span> <span class="fl">30.4</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">m2 =</span> <span class="fl">21.4</span>,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd1 =</span> <span class="fl">22.53</span>,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd2 =</span> <span class="fl">19.59</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">n1 =</span> <span class="dv">96</span>,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">n2 =</span> <span class="dv">96</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fl">0.05</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.426 0.140 0.712</code></pre>
</div>
</div>
<p>The output shows that the effect size is <span class="math inline">\(d_p\)</span> = 0.43, 95% CI [0.14, 0.71].</p>
</section>
<section id="standardize-by-control-group-standard-deviation-d_delta" class="level4">
<h4 class="anchored" data-anchor-id="standardize-by-control-group-standard-deviation-d_delta">Standardize by Control Group Standard Deviation (<span class="math inline">\(d_{\Delta}\)</span>)</h4>
<p>When two groups differ substantially in their standard deviations, we can instead standardize by the control group standard deviation (<span class="math inline">\(S_C\)</span>), such that,</p>
<p><span class="math display">\[
d_{\Delta} = \frac{M_T-M_C}{S_C}.
\]</span></p>
<p>Where the subscripts, <span class="math inline">\(T\)</span> and <span class="math inline">\(C\)</span>, denotes the treatment group and control group, respectively. This formulation is commonly referred to as Glass’ <span class="math inline">\(\Delta\)</span> <span class="citation" data-cites="glass1981">(<a href="#ref-glass1981" role="doc-biblioref">Glass 1981</a>)</span>. The standard error for <span class="math inline">\(d_{\Delta}\)</span> can be defined as,</p>
<p><span class="math display">\[
SE_{d_{\Delta}} = \sqrt{\frac{n_T+n_C}{n_T n_C} + \frac{d_\Delta^2}{n_C+1} }
\]</span></p>
<p>Notice that when we only standardize by the standard deviation of the control group (rather than pooling), we he will have less degrees of freedom (<span class="math inline">\(df=n_C-1\)</span>) and therefore more sampling error than we do when we divide by the pooled standard deviation (<span class="math inline">\(df= n_T + n_C - 2\)</span>).In R, we can use the <code>delta.ind.t.diff</code> function from the <code>MOTE</code> package to calculate <span class="math inline">\(d_\Delta\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's dz for difference scores</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># given difference score means and SDs</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Control group Mean = 30.4, SD = 22.53, N = 96</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment group Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation between conditions: r = .40</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">delta.ind.t</span>(</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">m1 =</span> <span class="fl">30.4</span>,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">m2 =</span> <span class="fl">21.4</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd1 =</span> <span class="fl">22.53</span>,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd2 =</span> <span class="fl">19.59</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">n1 =</span> <span class="dv">96</span>,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">n2 =</span> <span class="dv">96</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fl">0.05</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.399 0.140 0.712</code></pre>
</div>
</div>
</section>
</section>
<section id="repeated-measures-designs" class="level3">
<h3 class="anchored" data-anchor-id="repeated-measures-designs">Repeated Measures Designs</h3>
<p>In a repeated measures design, the same subjects are measured on two separate occasions and we want to know the mean difference between those two occasions. An example of this would be in a pre/post comparison where subjects are tested before and after undergoing some treatment (see <a href="#fig-repeatedmeasures">Figure&nbsp;1</a> for a visualization). A standardized mean difference in a repeated measures design can take on a few different forms that we define below.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-repeatedmeasures" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-repeatedmeasures-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Figure displaying simulated data of a repeated measures design, the x-axis shows the condition (e.g., pre-test and post-test) and y-axis is the scores. Lines connect the change within subject from one condition to the next.</figcaption>
</figure>
</div>
</div>
</div>
<section id="difference-score-d-d_z" class="level4">
<h4 class="anchored" data-anchor-id="difference-score-d-d_z">Difference Score <span class="math inline">\(d\)</span> (<span class="math inline">\(d_z\)</span>)</h4>
<p>Instead of comparing the means of two sets of scores, a within subject design allows us to subtract the scores obtained in condition 1 from the scores in condition 2. These difference scores (<span class="math inline">\(X_{\text{diff}}=X_2-X_1\)</span>) can be used similarly to the single group design (if the target value was zero, i.e., <span class="math inline">\(C=0\)</span>) such that,</p>
<p><span class="math display">\[
d_z = \frac{M_{\text{diff}}}{S_{\text{diff}}}
\]</span></p>
<p>Where the difference between this formulation and the single group design is the nature of the scores (difference scores rather than raw scores). The convenient thing about <span class="math inline">\(d_z\)</span> is that it has a straight-forward relationship with the <span class="math inline">\(t\)</span>-statistic, <span class="math inline">\(d_z=\frac{t}{\sqrt{n}}\)</span>. This makes it very useful for power analyses. If the standard deviation of difference scores are not accessible, then it can be calculated using the standard deviation of condition 1 (<span class="math inline">\(S_1\)</span>), the standard deviation of condition 2 (<span class="math inline">\(S_2\)</span>), and the correlation between conditions (<span class="math inline">\(r\)</span>):</p>
<p><span class="math display">\[
S_{\text{diff}}=\sqrt{S^2_1 + S^2_2 - 2 r S_1 S_2}
\]</span></p>
<p>It is important to note that when the correlation between groups is large, then the <span class="math inline">\(d_z\)</span> value will also be larger, whereas a small correlation will return a smaller <span class="math inline">\(d_z\)</span> value. The standard error of <span class="math inline">\(d_z\)</span> can be calculated similarly to the single group design such that,</p>
<p><span class="math display">\[
SE_{d_z} = \sqrt{\frac{1}{n}+\frac{d_z^2}{2n}}
\]</span></p>
<p>In R, we can use the <code>d.ind.t.diff</code> function from the <code>MOTE</code> package to calculate <span class="math inline">\(d_z\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's dz for difference scores</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># given difference score means and SDs</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Difference Score Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MOTE)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">d.dep.t.diff</span>(</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">m =</span> <span class="fl">21.4</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="fl">19.59</span>,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">96</span>,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fl">0.05</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 1.092 0.837 1.344</code></pre>
</div>
</div>
<p>The output shows that the effect size is <span class="math inline">\(d_z\)</span> = 1.09, 95% CI [0.84, 1.34].</p>
</section>
<section id="repeated-measures-d-d_rm" class="level4">
<h4 class="anchored" data-anchor-id="repeated-measures-d-d_rm">Repeated Measures <span class="math inline">\(d\)</span> (<span class="math inline">\(d_{rm}\)</span>)</h4>
<p>For a within-group design, we want to compare the means of scores obtained from condition 1 and condition 2. The repeated measures standardized mean difference between the two conditions can be calculated by,</p>
<p><span class="math display">\[
d_{rm} = \frac{M_2-M_1}{S_w}.
\]</span></p>
<p>A positive <span class="math inline">\(d_{rm}\)</span> value would indicate that the mean of condition 2 is larger than the mean of condition 1. The standardizer here is the within-subject standard deviation, <span class="math inline">\(S_w\)</span>. The within-subject standard deviation can be defined as,</p>
<p><span class="math display">\[
S_{\text{diff}}=\sqrt{\frac{S^2_1 + S^2_2 - 2 r S_1 S_2}{2(1-r)}}.
\]</span></p>
<p>We can also express <span class="math inline">\(S_w\)</span> in terms of <span class="math inline">\(S_{\text{diff}}\)</span>,</p>
<p><span class="math display">\[
S_w = \frac{S_{\text{diff}}}{ \sqrt{2(1-r)} }.
\]</span></p>
<p>Furthermore, we can even express <span class="math inline">\(d_{rm}\)</span> in terms of <span class="math inline">\(d_z\)</span>,</p>
<p><span class="math display">\[
d_{rm} = d_z \times \sqrt{2(1-r)}.
\]</span></p>
<p>Ultimately the <span class="math inline">\(d_{rm}\)</span> is more appropriate as an effect size estimate for use in meta-analysis whereas <span class="math inline">\(d_z\)</span> is more appropriate for power analysis <span class="citation" data-cites="lakens2013">(<a href="#ref-lakens2013" role="doc-biblioref">Lakens 2013</a>)</span>. The standard error for <span class="math inline">\(d_{rm}\)</span> can be computed as,</p>
<p><span class="math display">\[
SE_{d_{rm}} = \sqrt{\left(\frac{1}{n} + \frac{d^2_{rm}}{2n}\right) \times 2(1-r)}
\]</span></p>
<p>In R, we can use the <code>d.ind.t.rm</code> function from the <code>MOTE</code> package to calculate the repeated measures standardized mean difference (<span class="math inline">\(d_{rm}\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d for repeated measures</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># given means and SDs and correlation</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Condition 1 Mean = 30.4, SD = 22.53, N = 96</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Condition 2 Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation between conditions: r = .40</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">d.dep.t.rm</span>(</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">m1 =</span> <span class="fl">30.4</span>,</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">m2 =</span> <span class="fl">21.4</span>,</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd1 =</span> <span class="fl">22.53</span>,</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd2 =</span> <span class="fl">19.59</span>,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> .<span class="dv">40</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">96</span>,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fl">0.05</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.425 0.215 0.633</code></pre>
</div>
</div>
<p>The output shows that the effect size is <span class="math inline">\(d_{rm}\)</span> = 0.42, 95% CI [0.21, 0.63].</p>
</section>
<section id="average-variance-d-d_av" class="level4">
<h4 class="anchored" data-anchor-id="average-variance-d-d_av">Average Variance <span class="math inline">\(d\)</span> (<span class="math inline">\(d_{av}\)</span>)</h4>
<p>The problem with <span class="math inline">\(d_{z}\)</span> and <span class="math inline">\(d_{rm}\)</span>, is that they require the correlation between conditions. In practice, correlations between conditions are frequently not reported. An alternative estimator of Cohen’s <span class="math inline">\(d\)</span> in repeated measures design is to simply use the classic variation of cohen’s <span class="math inline">\(d\)</span> (i.e., pooled standard deviation). In a repeated measures design, the sample size does not change between conditions. Therefore weighting the variance of condition 1 and condition 2 by their respective degrees of freedom (i.e., <span class="math inline">\(df=n-1\)</span>) is an unnecessary step. Instead, we can standardize by the square root of the average the variances of condition 1 and 2:</p>
<p><span class="math display">\[
d_{av} = \frac{M_2 - M_1}{\sqrt{\frac{S_1^2 + S_2^2}{2}}}
\]</span></p>
<p>This formulation is convenient especially when the correlation is not present, however without the correlation it fails to take into account the consistency of change between conditions. The standard error of the <span class="math inline">\(d_{av}\)</span> can be expressed as,</p>
<p><span class="math display">\[
SE_{d_{av}}= \sqrt{\frac{2}{n} + \frac{d^2_{av}}{4n}}
\]</span></p>
<p>In R, we can use the <code>d.ind.t.rm</code> function from the <code>MOTE</code> package to calculate the repeated measures standardized mean difference (<span class="math inline">\(d_{rm}\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d for repeated measures (average variance)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># given means and SDs </span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Condition 1 Mean = 30.4, SD = 22.53, N = 96</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Condition 2 Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">d.dep.t.avg</span>(</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">m1 =</span> <span class="fl">30.4</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">m2 =</span> <span class="fl">21.4</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd1 =</span> <span class="fl">22.53</span>,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd2 =</span> <span class="fl">19.59</span>,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">96</span>,</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">a =</span> <span class="fl">0.05</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>d), </span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dlow), </span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(stats<span class="sc">$</span>dhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.427 0.217 0.635</code></pre>
</div>
</div>
<p>The output shows that the effect size is <span class="math inline">\(d_{av}\)</span> = 0.43, 95% CI [0.22, 0.64].</p>
</section>
<section id="beckers-d-d_b" class="level4">
<h4 class="anchored" data-anchor-id="beckers-d-d_b">Becker’s <span class="math inline">\(d\)</span> (<span class="math inline">\(d_b\)</span>)</h4>
<p>An even simpler variant of repeated measures <span class="math inline">\(d\)</span> value comes from <span class="citation" data-cites="becker1988">Becker (<a href="#ref-becker1988" role="doc-biblioref">1988</a>)</span>. Becker’s <span class="math inline">\(d\)</span> standardizes simply by the pre-test standard deviation when the comparison is a pre/post design,</p>
<p><span class="math display">\[
d_b = \frac{M_{\text{post}}-M_{\text{pre}}}{S_{\text{pre}}}.
\]</span></p>
<p>The convenient interpretation of “change in baseline standard deviations” can be quite a useful. We can also obtain the standard error with,</p>
<p><span class="math display">\[
SE_{d_b} = \sqrt{\frac{2(1-r)}{n}+\frac{d_b^2}{2n}}
\]</span> Notice that even though the formula for calculating <span class="math inline">\(d_b\)</span> did not include the correlation coefficient, the standard error does.</p>
<p>In base R, we can calculate Becker’s formulation of standardized mean difference using the equations above.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package below if not done so already</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(escalc)</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d for repeated measures (becker's d)</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># given means, the pre-test SDs, and the correlation</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># For example:</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-test Mean = 21.4, SD = 19.59, N = 96</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Post-test Mean = 30.4, N = 96</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation between conditions: r = .40</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>Mpre <span class="ot">&lt;-</span> <span class="fl">21.4</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>Mpost <span class="ot">&lt;-</span> <span class="fl">30.4</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>Spre <span class="ot">&lt;-</span> <span class="fl">19.59</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> .<span class="dv">40</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">96</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> (Mpost <span class="sc">-</span> Mpre) <span class="sc">/</span> Spre</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fu">sqrt</span>( <span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>r)<span class="sc">/</span>n <span class="sc">+</span> d<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>n) )</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>stats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">d =</span> d,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>                    <span class="at">dlow =</span> d <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>SE,</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>                    <span class="at">dhigh =</span> d <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>SE)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(d), </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(d <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>SE), </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(d <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>SE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.459 0.231 0.688</code></pre>
</div>
</div>
<p>The output shows that the effect size is <span class="math inline">\(d_{rm}\)</span> = 0.46, 95% CI [0.23, 0.69].</p>
</section>
<section id="comparing-repeated-measures-d-values" class="level4">
<h4 class="anchored" data-anchor-id="comparing-repeated-measures-d-values">Comparing Repeated Measures <span class="math inline">\(d\)</span> values</h4>
<p><a href="#fig-correlation-comp">Figure&nbsp;2</a> shows repeated measures designs with a high (<span class="math inline">\(r=\)</span> .95) and low (<span class="math inline">\(r=\)</span> .05) correlation between conditions. Let us fix the standard deviations and means for both conditions (i.e., high and low correlation) and only vary the correlation. Now we can compare the repeated measures estimators based on these two conditions shown in <a href="#fig-correlation-comp">Figure&nbsp;2</a>:</p>
<ul>
<li>High correlation:
<ul>
<li><span class="math inline">\(d_z=1.24\)</span></li>
<li><span class="math inline">\(d_{rm}=0.39\)</span></li>
<li><span class="math inline">\(d_{av}=0.43\)</span></li>
<li><span class="math inline">\(d_{b}=0.40\)</span></li>
</ul></li>
<li>Low correlation:
<ul>
<li><span class="math inline">\(d_z=0.31\)</span></li>
<li><span class="math inline">\(d_{rm}=0.43\)</span></li>
<li><span class="math inline">\(d_{av}=0.43\)</span></li>
<li><span class="math inline">\(d_{b}=0.40\)</span></li>
</ul></li>
</ul>
<p>We notice that the correlation greatly influences <span class="math inline">\(d_z\)</span> more than any other estimator. The <span class="math inline">\(d_{rm}\)</span> value has very little change, whereas <span class="math inline">\(d_{av}\)</span> and <span class="math inline">\(d_{b}\)</span> do not take into account the correlation at all.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-correlation-comp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-correlation-comp-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Figure displaying simulated data of a repeated measures design, the x-axis shows the condition (e.g., pre-test and post-test) and y-axis is the scores. Lines connect the change within subject from one condition to the next.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="small-sample-bias-in-d-values" class="level3">
<h3 class="anchored" data-anchor-id="small-sample-bias-in-d-values">Small Sample Bias in <span class="math inline">\(d\)</span> values</h3>
<p>All the estimators of <span class="math inline">\(d\)</span> listed above are biased estimates of the population <span class="math inline">\(d\)</span> value, specifically they all over-estimate the population value in small sample sizes. To adjust for this bias, we can apply a correction factor based on the degrees of freedom. The degrees of freedom will largely depend on the estimator used. The degrees of freedom for each estimator is listed below:</p>
<ul>
<li>Single Group design (<span class="math inline">\(d_s\)</span>): <span class="math inline">\(df = n-1\)</span></li>
<li>Between Groups - Pooled Standard Deviation (<span class="math inline">\(d_p\)</span>): <span class="math inline">\(df = n_1+n_2-2\)</span></li>
<li>Between Groups - Control Group Standard Deviation (<span class="math inline">\(d_\Delta\)</span>): <span class="math inline">\(df = n_C-1\)</span></li>
<li>Repeated Measures - all types (<span class="math inline">\(d_z\)</span>, <span class="math inline">\(d_{rm}\)</span>, <span class="math inline">\(d_{av}\)</span>, <span class="math inline">\(d_{b}\)</span>): <span class="math inline">\(df = n-1\)</span></li>
</ul>
<p>With the appropriate degrees of freedom, we can use the following correction factor, <span class="math inline">\(CF\)</span>, to obtain an unbiased estimate of the population standardized mean difference:</p>
<p><span class="math display">\[
CF = \frac{\Gamma\left(\frac{df}{2}\right)}{\Gamma\left(\frac{df-1}{2}\right)\sqrt{\frac{df}{2}}}
\]</span></p>
<p>Where <span class="math inline">\(\Gamma(\cdot)\)</span> is the gamma function. An approximation of this complex formula given by <span class="citation" data-cites="hedges1981">Hedges (<a href="#ref-hedges1981" role="doc-biblioref">1981</a>)</span> can be written as <span class="math inline">\(CF\approx 1-\frac{3}{4\cdot df -1}\)</span>. In R, this can be calculated using,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 1 sample size = 20</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Group 2 sample size = 18</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">18</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> n1 <span class="sc">+</span> n2 <span class="sc">-</span> <span class="dv">2</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>CF <span class="ot">&lt;-</span> <span class="fu">gamma</span>(df<span class="sc">/</span><span class="dv">2</span>) <span class="sc">/</span> ( <span class="fu">sqrt</span>(df<span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> <span class="fu">gamma</span>((df<span class="dv">-1</span>)<span class="sc">/</span><span class="dv">2</span>) )</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>CF</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9789964</code></pre>
</div>
</div>
<p>This correction factor can then be applied to any of the estimators mentioned above,</p>
<p><span class="math display">\[
d^* = d\times CF
\]</span></p>
<p>The corrected <span class="math inline">\(d\)</span> value, <span class="math inline">\(d^*\)</span>, is commonly referred to as Hedges’ <span class="math inline">\(g\)</span> or just <span class="math inline">\(g\)</span>. To avoid notation confusion we will just add an asterisk to <span class="math inline">\(d\)</span> to denote the correction. We also need to correct the standard error for <span class="math inline">\(d^*\)</span></p>
<p><span class="math display">\[
SE_{d^*} = SE_{d} \times CF
\]</span></p>
<p>These standard errors can then be used to calculate the confidence interval of the corrected <span class="math inline">\(d\)</span> value as well using <a href="#eq-ci-low">Equation&nbsp;1</a> and <a href="#eq-ci-high">Equation&nbsp;2</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Cohen's d = .50, SE = .10</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> .<span class="dv">50</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">=</span> .<span class="dv">10</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># correct d value and CIs small sample bias</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>d_corrected <span class="ot">&lt;-</span> d <span class="sc">*</span> CF</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>SE_corrected <span class="ot">&lt;-</span> SE <span class="sc">*</span> CF</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>dlow_corrected <span class="ot">&lt;-</span> d_corrected <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>SE_corrected</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>dhigh_corrected <span class="ot">&lt;-</span> d_corrected <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>SE_corrected</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print just the d value and confidence intervals</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">d =</span> <span class="fu">apa</span>(d), </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>           <span class="at">dlow =</span> <span class="fu">apa</span>(dlow_corrected), </span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>           <span class="at">dhigh =</span> <span class="fu">apa</span>(dhigh_corrected))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      d  dlow dhigh
1 0.500 0.298 0.681</code></pre>
</div>
</div>
<p>The output shows that the corrected effect size is <span class="math inline">\(d^*\)</span> = 0.50, 95% CI [0.30, 0.68].</p>
</section>
</section>
<section id="correlation-between-two-continuous-variables" class="level2">
<h2 class="anchored" data-anchor-id="correlation-between-two-continuous-variables">Correlation between Two Continuous Variables</h2>
<p>To quantify the relationship between two continuous variables, the most common method is to use a Pearson correlation coefficient (denoted with the letter <span class="math inline">\(r\)</span>). The pearson correlation takes the covariance between a continuous independent (<span class="math inline">\(X\)</span>) and dependent (<span class="math inline">\(Y\)</span>) variable and standardizes it by the standard deviations of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>,</p>
<p><span class="math display">\[
r = \frac{\text{Cov}(X,Y)}{S_{X} S_{Y}}.
\]</span></p>
<p>We can visualize what a correlation between two variables looks like with scatter plots. <a href="#fig-cor-example">Figure&nbsp;3</a> shows scatter plots with differing levels of correlation.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cor-example" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-cor-example-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Simulated data from a bivariate normal distribution displaying 6 different correlations, r = 0, .20, .40, .60, .80, and 1.00.</figcaption>
</figure>
</div>
</div>
</div>
<p>The standard error of the Pearson correlation coefficient is,</p>
<p><span class="math display">\[
SE_r = \sqrt{\frac{1-r^2}{n-2}}
\]</span></p>
<p>Unlike Cohen’s <span class="math inline">\(d\)</span> and other effect size measures, The correlation coefficient is bounded by -1 and positive 1, with positive 1 being a perfectly positive correlation, -1 being a perfectly negative correlation, and zero indicating no correlation between the two variables. The bounding has the consequence of making the confidence interval asymmetric around <span class="math inline">\(r\)</span> (e.g., if the correlation is positive, the lower bound is farther away from <span class="math inline">\(r\)</span> than the upper bound is). It is important to note that with a correlation of zero, the confidence interval <em>is</em> symmetric and normal. This asymmetric does not allow us to calculate the confidence intervals like how we did in <a href="#eq-ci-low">Equation&nbsp;1</a> and <a href="#eq-ci-high">Equation&nbsp;2</a>. Instead, to obtain the confidence intervals of <span class="math inline">\(r\)</span>, we first need to apply a Fisher’s Z transformation. A Fisher’s Z is a hyperbolic arctangent transformation of a Pearson correlation coefficient and can be computed as,</p>
<p><span class="math display">\[
Z_r = \text{arctanh}(r)
\]</span></p>
<p>The Fisher Z transformation ensures <span class="math inline">\(Z\)</span> has a symmetric and approximately normal sampling distribution. This then allows us to calculate the confidence interval from the standard error of <span class="math inline">\(Z_r\)</span> (<span class="math inline">\(SE_{Z_r} = \frac{1}{\sqrt{n-3}}\)</span>),</p>
<p><span class="math display">\[
CI_{Z_r} = Z_r \pm 1.96\times SE_{Z_r}
\]</span></p>
<p>We can then back-transform the upper bound and lower bound into the upper and lower bound of <span class="math inline">\(r\)</span> by taking the hyperbolic tangent (the inverse of the arctangent),</p>
<p><span class="math display">\[
r_{LO} = \text{tanh}(Z_{LO})
\]</span></p>
<p><span class="math display">\[
r_{UP} = \text{tanh}(Z_{UP})
\]</span></p>
<p>In R, the full process of obtaining confidence intervals can be done quite easily. Note if you have raw data for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, then you can compute the correlation with base R, <code>cor(X,Y)</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># example: r = .50, n = 50</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> .<span class="dv">50</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compute Zr</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>Zr <span class="ot">&lt;-</span> <span class="fu">atanh</span>(r)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate standard error of Zr</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>SE_Zr <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(n<span class="dv">-3</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co"># compute confidence interval of Zr</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>Zlow <span class="ot">&lt;-</span> Zr <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> SE_Zr</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>Zhigh <span class="ot">&lt;-</span> Zr <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> SE_Zr</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co"># backtransform CI of Z to CI of Pearson correlation</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>rlow <span class="ot">&lt;-</span> <span class="fu">tanh</span>(Zlow) </span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>rhigh <span class="ot">&lt;-</span> <span class="fu">tanh</span>(Zhigh)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print pearson correlation and confidence intervals</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">r =</span> <span class="fu">apa</span>(r), </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">rlow =</span> <span class="fu">apa</span>(rlow), </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>           <span class="at">rhigh =</span> <span class="fu">apa</span>(rhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      r  rlow rhigh
1 0.500 0.257 0.683</code></pre>
</div>
</div>
<p>The output shows that the correlation and its confidence intervals are <span class="math inline">\(r\)</span> = 0.50, 95% CI [0.26, 0.68].</p>
</section>
<section id="effect-sizes-for-categorical-variables" class="level2">
<h2 class="anchored" data-anchor-id="effect-sizes-for-categorical-variables">Effect Sizes for Categorical Variables</h2>
<p>For dichotomous relationships that involve proportions, there are many variations of effect sizes that one can use. Commonly used effect size measures for statistical procedures on categorical data include: phi coefficient (<span class="math inline">\(\phi\)</span>), Cramer’s <span class="math inline">\(V\)</span>, Cohen’s <span class="math inline">\(h\)</span>, Cohen’s <span class="math inline">\(\omega\)</span>, odds ratio (<span class="math inline">\(OR\)</span>), risk difference (<span class="math inline">\(RD\)</span>), and relative risk (<span class="math inline">\(RR\)</span>).</p>
<section id="phi-coefficient-phi" class="level3">
<h3 class="anchored" data-anchor-id="phi-coefficient-phi">Phi Coefficient (<span class="math inline">\(\phi\)</span>)</h3>
<p>Phi coefficient (<span class="math inline">\(\phi\)</span>) is a measure of association between two binary variables (therefore, it ONLY applies to 2 by 2 contingency tables, i.e., each variable has only two levels). It is a special case of the Pearson correlation coefficient and an <span class="math inline">\(r\)</span> for two binary variables is equal to phi. Note that unlike <span class="math inline">\(r\)</span> that ranges from -1 to 1, phi ranges from 0 to 1. Also, the sign of <span class="math inline">\(r\)</span> indicates the direction of association, whereas to get the direction of an association given a 2 by 2 contingency table, we need to look at the table itself; phi only provides a measure of strength. The 2 by 2 contingency table is illustrated by <a href="#tbl-contingency">Table&nbsp;1</a>.</p>
<div id="tbl-contingency" class="anchored">
<table class="table">
<caption>Table&nbsp;1: Contingency table between two binary variables</caption>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="math inline">\(X=0\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(Y=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{00}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{10}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(Y=1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{01}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{11}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>The sample sizes within each cell provide us with the necessary information to estimate the relationship between the two variables. A large phi coefficient would be expected to have relatively large sample sizes in the diagonal cells (<span class="math inline">\(n_{00}\)</span> and <span class="math inline">\(n_{11}\)</span>) and relatively low sample sizes in the off-diagonal cells (<span class="math inline">\(n_{01}\)</span> and <span class="math inline">\(n_{10}\)</span>). To calculate phi, it can be calculated from the cells of the contingency table directly,</p>
<p><span class="math display">\[
\phi = \frac{n_{11}n_{00} -n_{10}n_{01}}{\sqrt{(n_{00} + n_{01})(n_{10} + n_{11})(n_{00} + n_{10})(n_{01} + n_{11})}}
\]</span></p>
<p>or more conveniently, from the <span class="math inline">\(\chi^2\)</span>-statistic,</p>
<p><span class="math display">\[
\phi = \sqrt{\frac{\chi^2}{n}}
\]</span></p>
<p>Where <span class="math inline">\(n\)</span> is the total sample size (i.e., the sum of all the cells). Using the <code>psych</code> package in R, we can calculate the the phi coefficient using the <code>phi</code> function directly from the contingency table</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example contingency table:</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  40  17</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  11  45</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">40</span>, <span class="dv">11</span>,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">17</span>, <span class="dv">45</span>),<span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>phi_coefficient <span class="ot">&lt;-</span> <span class="fu">phi</span>(contingency_table)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>phi_coefficient</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.51</code></pre>
</div>
</div>
<p>In our example we obtained a phi coefficient of <span class="math inline">\(\phi\)</span> = .51.</p>
</section>
<section id="cramers-v" class="level3">
<h3 class="anchored" data-anchor-id="cramers-v">Cramer’s <span class="math inline">\(V\)</span></h3>
<p>Cramer’s V, sometimes also referred to as Cramer’s phi (<span class="math inline">\(\phi\)</span>), is a generalized effect size measure of the association between two nominal variables. It applies to contingency tables of any size (<span class="math inline">\(2\times 2\)</span>, <span class="math inline">\(3\times 3\)</span>, <span class="math inline">\(3\times 4\)</span>, <span class="math inline">\(5\times 3\)</span>, etc.). Cramer’s <span class="math inline">\(V\)</span> on a <span class="math inline">\(2\times 2\)</span> contingency table is equivalent to the phi coefficient. For an illustration of a higher order contingency table, <a href="#tbl-contingency-2">Table&nbsp;2</a> represents a <span class="math inline">\(3\times 4\)</span> contingency table of two variables.</p>
<div id="tbl-contingency-2" class="anchored">
<table class="table">
<caption>Table&nbsp;2: Contingency table between two categorical variables</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">\(X=0\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X=1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X=2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X=3\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(Y=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{00}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{10}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{21}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{31}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(Y=1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{01}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{11}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{21}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{31}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(Y=2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{02}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{12}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{22}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{32}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Similarly to the phi coefficient, the value of Cramer’s <span class="math inline">\(V\)</span> ranges from 0 to 1 and can interpreted in a similar way to a phi coefficient. Again we can use the <span class="math inline">\(\chi^2\)</span> statistic to compute the value, however, since there can be more than 2 levels to each variable, we also need to take into account the number of levels, <span class="math inline">\(k\)</span>, of the variable with the least number of levels (e.g., a 3$$4 continency table, <span class="math inline">\(k\)</span> would be equal to 3),</p>
<p><span class="math display">\[
V = \sqrt{\frac{\chi^2}{n(k-1)}}
\]</span></p>
<p>The standard error of a Cramer’s <span class="math inline">\(V\)</span> is similar to that of a Pearson correlation and a <span class="math inline">\(\phi\)</span> coefficient.</p>
<p><span class="math display">\[
SE_V = \sqrt{\frac{1-V^2}{n-2}}
\]</span></p>
<p>Where <span class="math inline">\(n\)</span> is the total sample size (i.e., the sum of all cells). Like the pearson correlation, we can not calculate the confidence interval directly from the standard error, instead, we must convert <span class="math inline">\(V\)</span> to a Fisher’s Z statistic, <span class="math inline">\(Z_V = \text{arctanh}(V)\)</span>. We can then calculate the standard errors and corresponding 95% confidence intervals for <span class="math inline">\(Z_V\)</span>:</p>
<p><span class="math display">\[
SE_{Z_V} = \frac{1}{\sqrt{n-3}}
\]</span> <span class="math display">\[
CI_{Z_V} = Z_V \pm 1.96\times SE_{Z_V}
\]</span></p>
<p>Then we can backtransform the upper and lower bound back into Cramer’s <span class="math inline">\(V\)</span>, such that <span class="math inline">\(V_{UP} = \text{tanh}(Z_{UP})\)</span> and <span class="math inline">\(V_{UP} = \text{tanh}(Z_{UP})\)</span>.</p>
<p>Using the <code>ufs</code> package <span class="citation" data-cites="ufs">(<a href="#ref-ufs" role="doc-biblioref">Peters and Gruijters 2023</a>)</span>, we can calculate Cramer’s <span class="math inline">\(V\)</span> and it’s 95% confidence interval using the Fisher’s Z method described above. For the example, we can example data from a 3$$3 contingency table.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example contingency table:</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  40  14  12</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  11  27   9</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   5  10  34</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ufs)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">40</span>, <span class="dv">11</span>,  <span class="dv">5</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">14</span>, <span class="dv">27</span>, <span class="dv">10</span>,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">12</span>,  <span class="dv">9</span>, <span class="dv">34</span>),<span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="fu">cramersV</span>(contingency_table)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>CI <span class="ot">&lt;-</span> <span class="fu">confIntV</span>(contingency_table)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print pearson correlation and confidence intervals</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">V =</span> <span class="fu">apa</span>(V<span class="sc">$</span>output<span class="sc">$</span>cramersV), </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>           <span class="at">Vlow =</span> <span class="fu">apa</span>(CI<span class="sc">$</span>output<span class="sc">$</span>confIntV.fisher[<span class="dv">1</span>]), </span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>           <span class="at">Vhigh =</span> <span class="fu">apa</span>(CI<span class="sc">$</span>output<span class="sc">$</span>confIntV.fisher[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      V  Vlow Vhigh
1 0.442 0.309 0.558</code></pre>
</div>
</div>
<p>In our example we obtained a Cramer’s <span class="math inline">\(V\)</span> of <span class="math inline">\(V\)</span> = .44 [.31, .56].</p>
</section>
<section id="cohens-h" class="level3">
<h3 class="anchored" data-anchor-id="cohens-h">Cohen’s <span class="math inline">\(h\)</span></h3>
<p>Cohen’s <span class="math inline">\(h\)</span> is a measure of distance between two proportions or probabilities. It is sometimes also referred to as the “difference between arcsines”. For a given proportion <span class="math inline">\(p\)</span>, its arcsine transformation is given by:</p>
<p><span class="math display">\[
\psi = 2\cdot \text{arcsin}(\sqrt{p}).
\]</span></p>
<p>Cohen’s <span class="math inline">\(h\)</span> is the difference between the arcsine transformations of two proportions:</p>
<p><span class="math display">\[
h = \psi_1 - \psi_2
\]</span></p>
<p>Cohen’s <span class="math inline">\(h\)</span> is commonly used for the power analysis of proportion tests. We can calculate the standard error in Cohen’s <span class="math inline">\(h\)</span> It is the required effect size measure in the program <em>G Power</em> <span class="citation" data-cites="faul2009">(<a href="#ref-faul2009" role="doc-biblioref">Faul et al. 2009</a>)</span>.</p>
<p><span class="math display">\[
SE_h = \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}
\]</span></p>
<p>Since the sampling distribution of <span class="math inline">\(h\)</span> is symmetric, we can calculate the confidence intervals as described previously in <a href="#eq-ci-low">Equation&nbsp;1</a> and <a href="#eq-ci-high">Equation&nbsp;2</a>,</p>
<p><span class="math display">\[
CI_h = h \pm1.96\times SE_h
\]</span></p>
<p>To calculate Cohen’s <span class="math inline">\(h\)</span>, we can use the <code>cohens_h</code> function in the <code>effectsize</code> package in R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install package if not done so already</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages('effectsize')</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example proportions: p1 = .45, p2 = .30</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(effectsize)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">40</span>, <span class="dv">11</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">14</span>, <span class="dv">27</span>),<span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="fu">cohens_h</span>(contingency_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cohen's h |       95% CI
------------------------
0.93      | [0.52, 1.34]</code></pre>
</div>
</div>
<p>From the example, the R code outputted a Cohen’s <span class="math inline">\(h\)</span> value of <span class="math inline">\(h\)</span> = .93 [0.52, 1.34].</p>
</section>
<section id="cohens-omega-omega" class="level3">
<h3 class="anchored" data-anchor-id="cohens-omega-omega">Cohen’s omega (<span class="math inline">\(\omega\)</span>)</h3>
<p>Although Cohen’s <span class="math inline">\(\omega\)</span> is useful for power analyses, it is not so useful as a stand-alone effect size. As <span class="citation" data-cites="cohen1988">Cohen (<a href="#ref-cohen1988" role="doc-biblioref">1988</a>)</span> states (pp.&nbsp;221):</p>
<blockquote class="blockquote">
<p>As a measure of association, [Cohen’s <span class="math inline">\(\omega\)</span>] lacks familiarity and convenience</p>
</blockquote>
<p>Cohen’s <span class="math inline">\(\omega\)</span> has the exact same formula as the phi coefficient with the only difference being that the <span class="math inline">\(\chi^2\)</span> statistic comes from a contingency table of any size,</p>
<p><span class="math display">\[
\omega = \sqrt{\frac{\chi^2}{n}}
\]</span></p>
<p>And can also be calculated directly from Cramer’s <span class="math inline">\(V\)</span>,</p>
<p><span class="math display">\[
\omega = V \times \sqrt{k-1}
\]</span></p>
<p>Where <span class="math inline">\(k\)</span> is the number of categories in the variable with the least number of categories.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example contingency table</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">40</span>, <span class="dv">11</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">14</span>, <span class="dv">27</span>),<span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cohens_w</span>(contingency_table,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cohen's w |       95% CI
------------------------
0.45      | [0.24, 0.65]</code></pre>
</div>
</div>
<p>From the example code, the <code>cohens_w</code> function returned Cohen’s <span class="math inline">\(\omega\)</span> value of <span class="math inline">\(h\)</span> = .93 [0.52, 1.34].</p>
</section>
<section id="ben-shachars-fei-פ" class="level3">
<h3 class="anchored" data-anchor-id="ben-shachars-fei-פ">Ben-Shachar’s Fei (פ)</h3>
<p><span class="citation" data-cites="benshachar2023">Ben-Shachar et al. (<a href="#ref-benshachar2023" role="doc-biblioref">2023</a>)</span> introduced a new effect size for contingency tables that they label with the Hebrew letter, פ. Ben-Shachar’s פ is a correction to Cohen’s <span class="math inline">\(\omega\)</span> that adjusts for the expected value and consequently bounds the value between 0 and 1 (Cohen’s <span class="math inline">\(\omega\)</span> is only bounded between 0 and 1 when marginal distributions are uniform).</p>
<p>Cohen’s <span class="math inline">\(\omega\)</span> has the exact same formula as the phi coefficient with the only difference being that the <span class="math inline">\(\chi^2\)</span> statistic comes from a contingency table of any size,</p>
<p><span class="math display">\[
\mathbf{פ }= \sqrt{\frac{\chi^2}{n \left(\frac{1}{\min\left(P_E\right)} -1\right)}}
\]</span></p>
<p>Where <span class="math inline">\(\min(P_E)\)</span> is the smallest expected probability in the contingency table. An expected probability for a given cell is the proportion of the total sample that would be expected to exist in that cell if the two variables were independent. The formula for Ben-Schacher’s פ can be also be expressed in terms of Cohen’s <span class="math inline">\(\omega\)</span>,</p>
<p><span class="math display">\[
\mathbf{פ }= \frac{\omega}{\sqrt{\left(\frac{1}{\max(P_E)} -1\right)}}
\]</span></p>
<p>In R, we can calculate Ben-Shacher’s פ using the <code>effectsize</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed counts: 20, 50, 100 (observed proportions: .12, .29, .59)</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected proportions: .5, .2, .3</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>observed_counts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">50</span>,<span class="dv">100</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>expected_probabilities <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">5</span>,.<span class="dv">2</span>,.<span class="dv">3</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="fu">fei</span>(observed_counts,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">p =</span> expected_probabilities,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fei  |       95% CI
-------------------
0.39 | [0.31, 0.47]

- Adjusted for uniform expected probabilities.</code></pre>
</div>
</div>
<p>From the example code, the <code>cohens_w</code> function returned Ben-Shacher’s פ value of .39 [0.31, 0.47].</p>
</section>
<section id="odds-ratio-or" class="level3">
<h3 class="anchored" data-anchor-id="odds-ratio-or">Odds Ratio (<span class="math inline">\(OR\)</span>)</h3>
<p>Odds ratio measures the effect size between two binary variables. It is commonly used in medical and behavioral intervention research, and notably, in meta-analysis.</p>
<p>Let’s imagine a study conducted to investigate the association between smoking and the development of major depressive disorder (MDD). The study includes a sample of 251 individuals, categorizing them into two groups: 125 smokers and 126 non-smokers. The researchers are interested in understanding the odds of having major depressive disorder (MDD) among smokers compared to non-smokers. Say we find that 25 smokers were diagnosed with MDD while 100 were not, but in the non-smoker group, 12 individuals were diagnosed with MDD while 120 were not. The odds ratio would then be:</p>
<p><span class="math display">\[
OR = \frac{25/100}{12/120}= \frac{.25}{.10} = 2.50
\]</span></p>
<p>In general, we can can compute the odds-ratio from a contingency table between binary variables <span class="math inline">\(X\)</span> (i.e., the treatment) and <span class="math inline">\(Y\)</span> (i.e., the outcome; see <a href="#tbl-contingency-OR">Table&nbsp;3</a>).</p>
<div id="tbl-contingency-OR" class="anchored">
<table class="table">
<caption>Table&nbsp;3: Contingency table between two binary variables</caption>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><span class="math inline">\(X=T\)</span></th>
<th style="text-align: center;"><span class="math inline">\(X=C\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(Y=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{T0}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{C0}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(Y=1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{T1}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{C1}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Ultimately, we want to compare the outcome between the treatment group (<span class="math inline">\(X=T\)</span>) and the control group (<span class="math inline">\(X=C\)</span>). Therefore we can compute the odds ratio as,</p>
<p><span class="math display">\[
OR = \frac{n_{T1}/n_{T0}}{n_{C1}/n_{C0}}
\]</span></p>
<p>The standard distribution of the odds-ratio is asymmetric. To calculate confidence intervals, we can first convert the odds ratio to a log odds ratio (<span class="math inline">\(LOR= \log(OR)\)</span>). Then we can calculate the standard error of the log odds ratio,</p>
<p><span class="math display">\[
SE_{LOR} = \sqrt{\frac{1}{n_{T0}} + \frac{1}{n_{T1}} + \frac{1}{n_{C0}} + \frac{1}{n_{C1}}}
\]</span></p>
<p>With the standard error of the log odds ratio we can then calculate the log odds ratio,</p>
<p><span class="math display">\[
LOR_{UP} = LOR - 1.96\times SE_{LOR}
\]</span></p>
<p>Then the final step we can convert these back to <span class="math inline">\(OR\)</span> confidence intervals by taking the exponential transformation of the upper and lower bounds: <span class="math inline">\(OR_{UP}=\exp(LOR_{UP})\)</span> and <span class="math inline">\(OR_{UP}=\exp(LOR_{UP})\)</span>.</p>
<p>In R, we can use the <code>effectsize</code> package to calculate the odds ratio and it’s confidence interval:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment Group: 10 diseased, 43 healthy</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Control Group:  24 diseased, 41 healthy</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">24</span>,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>                              <span class="dv">43</span>, <span class="dv">41</span>),<span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="fu">oddsratio</span>(contingency_table,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Odds ratio |       95% CI
-------------------------
0.40       | [0.17, 0.93]</code></pre>
</div>
</div>
<p>The code output for this example shows an odds ratio of <span class="math inline">\(OR\)</span> = 0.40 [0.17, 0.93]</p>
</section>
<section id="risk-difference-rd" class="level3">
<h3 class="anchored" data-anchor-id="risk-difference-rd">Risk Difference (<span class="math inline">\(RD\)</span>)</h3>
<p>Risk difference can be used to interpret the difference between two proportions. If we use the contingency table from <a href="#tbl-contingency-OR">Table&nbsp;3</a>, and calculate a risk difference between the treatment group and the control group. We can first calculate the proportion of cases where the outcome is <span class="math inline">\(Y=1\)</span> <em>within</em> the control group and the treatment group:</p>
<p><span class="math display">\[
p_C=\frac{n_{C1}}{n_{C0}+n_{C1}}
\]</span></p>
<p><span class="math display">\[
p_T=\frac{n_{T1}}{n_{T0}+n_{T1}}
\]</span></p>
<p>Then using these proportions we can calculate the risk difference (<span class="math inline">\(RD\)</span>),</p>
<p><span class="math display">\[
RD = p_T - p_C.
\]</span> The corresponding standard error is,</p>
<p><span class="math display">\[
SE_{RD} = \sqrt{\frac{p_C(1-p_C)}{n_C} + \frac{p_T(1-p_T)}{n_T} }
\]</span></p>
<p>Where <span class="math inline">\(n_C\)</span> and <span class="math inline">\(n_T\)</span> are the total sample sizes <em>within</em> the control and treatment group, respectively. The standard error can then be used to compute the 95% confidence intervals,</p>
<p><span class="math display">\[
CI_{RD} = RD \pm 1.96 \times SE_{RD}
\]</span></p>
<p>The risk difference formula is fairly simple, so we can compute it using base R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: </span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment group: proportion of cases = .5, sample size = 40</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Control group: proportion of cases = .3, sample size = 45</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>pT <span class="ot">&lt;-</span> .<span class="dv">50</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>pC <span class="ot">&lt;-</span> .<span class="dv">30</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>nT <span class="ot">&lt;-</span> <span class="dv">40</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>nC <span class="ot">&lt;-</span> <span class="dv">45</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>RD <span class="ot">&lt;-</span> pT <span class="sc">-</span> pC</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fu">sqrt</span>( pC<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>pC)<span class="sc">/</span>nC <span class="sc">+</span> pT<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>pT)<span class="sc">/</span>nT )</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compute 95% CIs</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>RDlow <span class="ot">&lt;-</span> RD <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>SE</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>RDhigh <span class="ot">&lt;-</span> RD <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>SE</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">RD =</span> <span class="fu">apa</span>(RD),</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">RDlow =</span> <span class="fu">apa</span>(RDlow),</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">RDhigh =</span> <span class="fu">apa</span>(RDhigh)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RD  RDlow RDhigh
1 0.200 -0.005  0.405</code></pre>
</div>
</div>
</section>
<section id="relative-risk-rr" class="level3">
<h3 class="anchored" data-anchor-id="relative-risk-rr">Relative Risk (<span class="math inline">\(RR\)</span>)</h3>
<p>The relative risk, often referred to as the “risk ratio,” calculates the ratio between the proportion of cases in the treatment group and the proportion of cases in the control group. It provides a straightforward interpretation: “individuals receiving the treatment have a <span class="math inline">\(RR\)</span> times higher odds of experiencing the outcome compared to controls.” To calculate relative riskm, first we need to calculate the proportion of outcome cases in the treatment and control group</p>
<p><span class="math display">\[
p_C=\frac{n_{C1}}{n_{C0}+n_{C1}}
\]</span></p>
<p><span class="math display">\[
p_T=\frac{n_{T1}}{n_{T0}+n_{T1}}
\]</span></p>
<p>Then we can calculate the relative risk,</p>
<p><span class="math display">\[
RR=\frac{p_T}{p_C}
\]</span></p>
<p>The corresponding standard error can be computed as,</p>
<p><span class="math display">\[
SE_{RR} = \sqrt{\frac{p_T}{n_T} + \frac{p_C}{n_C}}
\]</span></p>
<p>The confidence intervals can be computed by adapting <strong>?@eq-ci</strong>,</p>
<p><span class="math display">\[
CI_{RR} = RR\pm 1.96\times SE_{RR}
\]</span></p>
<p>To compute relative risk, we can simply use the equations above in base R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment Group: 10 diseased, 43 healthy, 53 total</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Control Group:  24 diseased, 41 healthy, 65 total</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>pT <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">/</span>(<span class="dv">43</span><span class="sc">+</span><span class="dv">10</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>pC <span class="ot">&lt;-</span> <span class="dv">24</span><span class="sc">/</span>(<span class="dv">41</span><span class="sc">+</span><span class="dv">24</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>nT <span class="ot">&lt;-</span> <span class="dv">53</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>nC <span class="ot">&lt;-</span> <span class="dv">65</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>RR <span class="ot">&lt;-</span> pT <span class="sc">/</span> pC</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(pT<span class="sc">/</span>nT <span class="sc">+</span> pC<span class="sc">/</span>nC)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>RRlow <span class="ot">&lt;-</span> RR <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>SE</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>RRhigh <span class="ot">&lt;-</span> RR <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>SE</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print pearson correlation and confidence intervals</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">RR =</span> <span class="fu">apa</span>(RR), </span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>           <span class="at">RRlow =</span> <span class="fu">apa</span>(RRlow), </span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>           <span class="at">RRhigh =</span> <span class="fu">apa</span>(RRhigh))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RR RRlow RRhigh
1 0.511 0.323  0.699</code></pre>
</div>
</div>
</section>
</section>
<section id="effect-sizes-for-anovas" class="level2">
<h2 class="anchored" data-anchor-id="effect-sizes-for-anovas">Effect Sizes for ANOVAs</h2>
<p>ANOVA (Analysis of Variance) is a statistical method used to compare means across multiple groups. It is mostly used when the outcome variable is continuous and the predictor variables are categorical. Commonly used effect size measures for ANOVAs / F-tests include: eta-squared (<span class="math inline">\(\eta^2\)</span>), partial eta-squared (<span class="math inline">\(\eta_p^2\)</span>), generalized eta-squared (<span class="math inline">\(\eta^2_G\)</span>), omega-squared (<span class="math inline">\(\omega^2\)</span>), partial omega-squared (<span class="math inline">\(\omega\)</span>), generalized omega-squared (<span class="math inline">\(\omega^2_G\)</span>), Cohen’s <span class="math inline">\(f\)</span>.</p>
<section id="eta-squared-eta2" class="level3">
<h3 class="anchored" data-anchor-id="eta-squared-eta2">Eta-Squared (<span class="math inline">\(\eta^2\)</span>)</h3>
<p>Eta-squared is the ratio between the between-group variance and the total variance. It describes the proportion of the total variability in the data that are accounted for by a particular factor. Therefore, it is a measure of <em>variance explained</em>. To calculate eta-squared (<span class="math inline">\(\eta^2\)</span>) we need to first calculate the total sum of squares (<span class="math inline">\(SS_{\text{total}}\)</span>) and the effect sum of squares (<span class="math inline">\(SS_{\text{effect}}\)</span>),</p>
<p><span class="math display">\[
SS_{\text{total}} = \sum_{i=1}^n (y_i-\bar{y})^2
\]</span> Where <span class="math inline">\(\bar{y}\)</span> is the grand mean (i.e., the mean of all data points collapsed across groups). To calculate the sum of squares of the effect, we can take the predicted <span class="math inline">\(y\)</span> values (<span class="math inline">\(\hat{y}_i\)</span>). In the case of categorical predictors, <span class="math inline">\(\hat{y}_i\)</span> is equal to the mean of the outcome <em>within</em> that individual’s respective group. Therefore the sum of squares of the effect can be calculated using the following formula:</p>
<p><span class="math display">\[
SS_{\text{effect}} = \sum_{i=1}^n (\hat{y}_i-\bar{y})^2.
\]</span></p>
<p>Now we can calculate the eta-squared value,</p>
<p><span class="math display">\[
\eta^2 = \frac{SS_{\text{effect}}}{SS_{\text{total}}}
\]</span></p>
<p>The standard error of eta-square can be approximated from <span class="citation" data-cites="olkin1995">Olkin and Finn (<a href="#ref-olkin1995" role="doc-biblioref">1995</a>)</span>:</p>
<p><span class="math display">\[
SE_{\eta^2}=\sqrt{\frac{4\eta^2\left(1-\eta^2\right)^2\left(n+k-1\right)^2}{\left(n^2-1\right)\left(3+n\right)}}
\]</span></p>
<p>The sampling distribution for <span class="math inline">\(\eta^2\)</span> is asymmetric as all the values are bounded in the range, 0 to 1. The confidence interval surrounding <span class="math inline">\(\eta^2\)</span> will likewise be asymmetric so instead of calculating the confidence interval from the standard error, we can instead use a non-central F-distribution using the degrees of freedom between groups (e.g., for three groups: <span class="math inline">\(df_b=k-1=3-1=2\)</span>) and the degrees of freedom within groups (e.g., for 100 subjects and three groups: <span class="math inline">\(df_b=n-k=100-3=97\)</span>) to obtain the confidence intervals. Another option is to use bootstrapping procedure (i.e., resampling the observed data points to construct a sampling distribution around <span class="math inline">\(\eta^2\)</span>; see <span class="citation" data-cites="BootES">Kirby and Gerlanc (<a href="#ref-BootES" role="doc-biblioref">2013</a>)</span>) and then take the .025 and .975 quantiles of that distribution. The R code below will compute the proper confidence interval.</p>
<p>Where <span class="math inline">\(n\)</span> is the total sample size and <span class="math inline">\(k\)</span> is the number of predictors. In R, we can calculate <span class="math inline">\(\eta^2\)</span> from a one-way ANOVA using the penguin data set from the <code>palmerpenguins</code> data package. The <code>aov</code> function in base R allows the analyst to model an ANOVA with categorical predictors on the right side (species) of the <code>~</code> and the outcome on the left side (body mass of penguin). We can then use <code>eta_squared</code> function in the <code>effectsize</code> package to calculate the point estimate and confidence intervals.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(palmerpenguins)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># One-Way ANOVA</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>mdl1 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="fu">eta_squared</span>(mdl1, </span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">FALSE</span>,</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Eta2 |       95% CI
-------------------------------
species   | 0.67 | [0.62, 0.71]</code></pre>
</div>
</div>
<p>The species of the penguin explains the majority of the variation in body mass showing an eta-squared value of <span class="math inline">\(\eta^2\)</span> = .67 [.62, .71]. Let us now do the same thing with a two-way ANOVA, using both <code>species</code> and <code>sex</code> as our categorical predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species and sex</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Two-Way ANOVA</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>mdl2 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species <span class="sc">+</span> sex)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="fu">eta_squared</span>(mdl2, </span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">FALSE</span>,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Eta2 |       95% CI
-------------------------------
species   | 0.67 | [0.62, 0.72]
sex       | 0.17 | [0.10, 0.24]</code></pre>
</div>
</div>
<p>Notice that the <span class="math inline">\(\eta^2\)</span> does not change for species since the sum of squares is divided by the total sum of squares rather than the residual sum of squares (see partial eta squared). The example shows an eta-squared value for species of <span class="math inline">\(\eta^2\)</span> = .67 [.62, .72] and for sex <span class="math inline">\(\eta^2\)</span> = .17 [.10, .24].</p>
</section>
<section id="partial-eta-squared-eta2_p" class="level3">
<h3 class="anchored" data-anchor-id="partial-eta-squared-eta2_p">Partial Eta-Squared (<span class="math inline">\(\eta^2_p\)</span>)</h3>
<p>Partial eta-squared is the most commonly reported effect size measure for F-tests. It describes the proportion of variability associated with an effect when the variability associated with all other effects identified in the analysis has been removed from consideration (hence, it is “partial”). If you have access to an ANOVA table, the partial eta-squared for an effect is calculated as:</p>
<p><span class="math display">\[
\eta_p^2 = \frac{ SS_{\text{effect}}}{SS_{\text{effect}}+SS_{\text{error}}}
\]</span></p>
<p>There are two things to take note of here:</p>
<ol type="1">
<li>In a one-way ANOVA (one categorical predictor), partial eta-squared and eta-squared are equivalent since <span class="math inline">\(SS_{\text{total}} = SS_{\text{effect}}+SS_{\text{error}}\)</span></li>
<li>If there are multiple predictors, the denominator will only include the sum of squares of the effect of interest rather than the effect of all predictors (which is the case for the non-partial eta squared).</li>
</ol>
<p>In R, let us compare the partial eta-squared values for a one-way ANOVA and a two-way ANOVA using the <code>eta_squared</code> function in the <code>effectsize</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># One-Way ANOVA</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>mdl1 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="fu">eta_squared</span>(mdl1, </span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">TRUE</span>,</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>For one-way between subjects designs, partial eta squared is equivalent
  to eta squared. Returning eta squared.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA

Parameter | Eta2 |       95% CI
-------------------------------
species   | 0.67 | [0.62, 0.71]</code></pre>
</div>
</div>
<p>The species of the penguin explains the majority of the variation in body mass showing a partial eta-squared value of <span class="math inline">\(\eta^2\)</span> = <span class="math inline">\(\eta^2_p\)</span> = .67 [.62, .71]. Let us now do the same thing with a two-way ANOVA, using both <code>species</code> and <code>sex</code> as our categorical predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species and sex</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Two-Way ANOVA</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>mdl2 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species <span class="sc">+</span> sex)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="fu">eta_squared</span>(mdl2, </span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">TRUE</span>,</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Eta2 (partial) |       95% CI
-----------------------------------------
species   |           0.81 | [0.78, 0.84]
sex       |           0.53 | [0.46, 0.59]</code></pre>
</div>
</div>
<p>Once we run a two-way ANOVA, the eta-squared value for species begins to differ. The example shows a partial eta-squared value for species of <span class="math inline">\(\eta^2_p\)</span> = .81 [.78, .84] and for sex <span class="math inline">\(\eta^2\)</span> = .53 [.46, .59].</p>
</section>
<section id="generalized-eta-squared-eta2_g" class="level3">
<h3 class="anchored" data-anchor-id="generalized-eta-squared-eta2_g">Generalized Eta-Squared (<span class="math inline">\(\eta^2_G\)</span>)</h3>
<p>Generalized eta-squared was devised to allow effect size comparisons across studies with different designs, which eta-squared and partial eta-squared cannot help with (refer to for details). If you can (either you are confident that you calculated it right, or the statistical software that you use just happens to return this measure), report generalized eta-squared in addition to eta-squared or partial eta-squared. The biggest advantage of generalized eta-squared is that it facilitates meta-analysis, which is important for accumulation of knowledge. To calculate generalized eta-squared, the denominator should be the sums of squares of all the non-manipulated variables (i.e., variance of purely individual differences in the outcome rather than individual differences in treatment effects). Note the formula will depend on the design of the study. In R, the <code>eta_squared</code> function in the <code>effectsize</code> package supports the calculation generalized eta-squared by using the <code>generalized=TRUE</code> argument.</p>
</section>
<section id="omega-squared-corrections-omega2-omega2_p" class="level3">
<h3 class="anchored" data-anchor-id="omega-squared-corrections-omega2-omega2_p">Omega squared corrections (<span class="math inline">\(\omega^2\)</span>, <span class="math inline">\(\omega^2_p\)</span>)</h3>
<p>Similar to Hedges’ correction for small sample bias in standardized mean differences, <span class="math inline">\(\eta^2\)</span> is also biased. We can apply a correction to <span class="math inline">\(\eta^2\)</span> and obtain a relatively unbiased estimate of the population proportion of variance explained by the predictor. To calculate <span class="math inline">\(\omega\)</span>, we need to calculate the within group mean squared errors:</p>
<p><span class="math display">\[
MS_{\text{within}} = \frac{1}{n}\sum_{i=1}^n (y_i-\hat{y}_i)^2.
\]</span> Where the predicted values of the outcome, <span class="math inline">\(\hat{y}_i\)</span>, are the mean value for the individual’s respective group.</p>
<p><span class="math display">\[
\omega^2 = \frac{SS_{\text{effect}}-(k-1)\times MS_{\text{within}}}{SS_{\text{total}} + MS_{\text{within}}}
\]</span></p>
<p>Where <span class="math inline">\(k\)</span> is the number of groups in the predictor (effect) variable. For partial omega-squared values, we need the mean squared error of effect and the residuals which can easily be calculated from their sum of squares:</p>
<p><span class="math display">\[
MS_{\text{effect}} = \frac{SS_{\text{effect}}}{n}
\]</span> <span class="math display">\[
MS_{\text{error}} = \frac{SS_{\text{error}}}{n}
\]</span> Then to calculate the partial omega squared we can use the following formula:</p>
<p><span class="math display">\[
\omega_p^2 = \frac{(k-1)(MS_{\text{effect}} - MS_{\text{error}})}{(k-1)\times MS_{\text{effect}} + (n-k-1)\times MS_{\text{error}}}
\]</span></p>
<p>In R, we can use the <code>omega_squared</code> function in the <code>effectsize</code> package to calculate both <span class="math inline">\(\omega^2\)</span> and <span class="math inline">\(\omega^2_p\)</span>. For the first example we will use a one-way ANOVA.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(palmerpenguins)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># One-Way ANOVA</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>mdl1 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># omega-squared</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="fu">omega_squared</span>(mdl1, </span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">FALSE</span>,</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Omega2 |       95% CI
---------------------------------
species   |   0.67 | [0.61, 0.71]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># partial omega-squared</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">omega_squared</span>(mdl1, </span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">partial =</span> <span class="cn">TRUE</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>For one-way between subjects designs, partial omega squared is
  equivalent to omega squared. Returning omega squared.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA

Parameter | Omega2 |       95% CI
---------------------------------
species   |   0.67 | [0.61, 0.71]</code></pre>
</div>
</div>
<p>The species of the penguin explains the majority of the variation in body mass showing an omega-squared value of <span class="math inline">\(\omega^2\)</span> = .67 [.61, .71]. Note that the partial and non-partial omega squared values do not show a difference as expected in a one-way ANOVA. Let us now do the same thing with a two-way ANOVA, using both <code>species</code> and <code>sex</code> as our categorical predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species and sex</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Two-Way ANOVA</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>mdl2 <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species <span class="sc">+</span> sex)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="co"># omega-squared</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="fu">omega_squared</span>(mdl2, </span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">partial =</span> <span class="cn">FALSE</span>,</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Omega2 |       95% CI
---------------------------------
species   |   0.67 | [0.62, 0.72]
sex       |   0.17 | [0.10, 0.24]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># partial omega-squared</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">omega_squared</span>(mdl2, </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">partial =</span> <span class="cn">TRUE</span>,</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter | Omega2 (partial) |       95% CI
-------------------------------------------
species   |             0.81 | [0.78, 0.84]
sex       |             0.53 | [0.46, 0.58]</code></pre>
</div>
</div>
<p>Once we run a two-way ANOVA, the eta-squared value for species &nbsp;diverge. The example shows a partial eta-squared value for species of <span class="math inline">\(\omega^2_p\)</span> = .81 [.78, .84] and for sex <span class="math inline">\(\omega^2\)</span> = .53 [.46, .58].</p>
</section>
<section id="cohens-f" class="level3">
<h3 class="anchored" data-anchor-id="cohens-f">Cohen’s <span class="math inline">\(f\)</span></h3>
<p>Cohen’s <span class="math inline">\(f\)</span> is defined as the ratio of the standard deviations of the group means and the common standard deviation within each of the groups (note that ANOVA assumes equal variances among groups). Cohen’s <span class="math inline">\(f\)</span> is the effect size measure asked for by G*Power for power analysis for F-tests. This can be calculated easily from the eta-squared value,</p>
<p><span class="math display">\[
f = \sqrt{\frac{\eta^2}{1-\eta^2}}
\]</span></p>
<p>or by the <span class="math inline">\(\omega^2\)</span> value,</p>
<p><span class="math display">\[
f = \sqrt{\frac{\omega^2}{1-\omega^2}}
\]</span></p>
<p>Cohen’s <span class="math inline">\(f\)</span> can be interpreted as “the average Cohen’s <span class="math inline">\(d\)</span> (i.e., standardized mean difference) between groups”. Note that there is no directionality to this effect size (<span class="math inline">\(f\)</span> is always greater than zero), therefore two studies showing the same <span class="math inline">\(f\)</span> with the same groups, can have very different patterns of group mean differences. Note that Cohen’s <span class="math inline">\(f\)</span> is also often reported as <span class="math inline">\(f^2\)</span>. The confidence intervals for Cohen’s <span class="math inline">\(f\)</span> can be computed from the upper bounds and lower bounds of the confidence intervals from eta-square or omega-square using the formulas to calculate <span class="math inline">\(f\)</span> (e.g., for the upper bound <span class="math inline">\(f_{UP} = \sqrt{\frac{\eta^2_{UP}}{1-\eta^2_{UP}}}\)</span>).</p>
<p>In R, we can use the <code>cohens_f</code> function in the <code>effectsize</code> package to calculate Cohen’s <span class="math inline">\(f\)</span>. We will again use example data from the <code>palmerpenguins</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co"># group: species</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># outcome: body mass</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>mdl <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species)   </span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cohens_f</span>(mdl,<span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>For one-way between subjects designs, partial eta squared is equivalent
  to eta squared. Returning eta squared.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA

Parameter | Cohen's f |       95% CI
------------------------------------
species   |      1.42 | [1.27, 1.57]</code></pre>
</div>
</div>
<p>In the example above, the difference in body mass between the three penguin species was very large showing a Cohen’s <span class="math inline">\(f\)</span> of 1.42 [1.27, 1.57].</p>
</section>
<section id="reporting-anova-results" class="level3">
<h3 class="anchored" data-anchor-id="reporting-anova-results">Reporting ANOVA results</h3>
<p>For ANOVAs/F-tests, you will always need to report two kinds of effects: the omnibus effect of the factor(s) and the effect of planned contrasts or post hoc comparisons.</p>
<p>For instance, imagine that you are comparing three groups/conditions with a one-way ANOVA. The ANOVA will first return an F-statistic, the degrees of freedom, and the associated p-value. Here, you need to calculate the size of this omnibus factor effect in eta-squared, partial eta-squared, or generalized eta-squared. Suppose the omnibus effect is significant. You now know that there is at least one group that differs from the others. You want to know which group(s) differ from the others, and how much they differ. Therefore, you conduct post hoc comparisons on these groups. Because post hoc comparisons compare each group with the others in pairs, you will get a <em>t</em>-statistic and p-value for each comparison. For this, you need to calculate and report Cohen’s <span class="math inline">\(d\)</span> or Hedges’ <span class="math inline">\(g\)</span>.</p>
<p>Imagine that you have two independent variables or factors, and you conduct a two-by-two factorial ANOVA. The first thing to do then is look at the interaction. If the interaction is significant, you again report the associated omnibus effect size measures, and proceed to analyze the simple effects. Depending on your research question, you compare the levels of one IV on each level of the other IV. You will report d or g for these simple effects. If the interaction is not significant, you look at the main effects and report the associated omnibus effect. You then proceed to analyze the main effect by comparing the levels of one IV while collapsing/aggregating the levels of the other IV. You will report <span class="math inline">\(d\)</span> or <span class="math inline">\(g\)</span> for these pairwise comparisons.</p>
<p>Note that lower-order effects are not directly interpretable if higher-order effects are significant. If you have a significant interaction in a two-way ANOVA, you cannot interpret the main effects directly. If you have a significant three-way interaction in a three-way ANOVA, you cannot interpret the main effects or the two-way interactions directly, regardless of whether they are significant or not.</p>
<p>In R, we can use the <code>summary</code> function to display the anova table. We can also append the table to include, for example, partial omega squared values and their respective confidence intervals</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA mdl</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>mdl <span class="ot">&lt;-</span> <span class="fu">aov</span>(<span class="at">data =</span> penguins,</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>           body_mass_g <span class="sc">~</span> species <span class="sc">+</span> sex)   </span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate partial omega-squared values</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>omega_values <span class="ot">&lt;-</span> <span class="fu">omega_squared</span>(mdl, <span class="at">alternative =</span> <span class="st">"two.sided"</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co"># create table of partial omega-squared values</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>omega_table <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">omega_sq =</span> <span class="fu">apa</span>(<span class="fu">c</span>(omega_values<span class="sc">$</span>Omega2_partial,<span class="cn">NA</span>)),</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">omega_low =</span> <span class="fu">apa</span>(<span class="fu">c</span>(omega_values<span class="sc">$</span>CI_low,<span class="cn">NA</span>)),</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">omega_high =</span> <span class="fu">apa</span>(<span class="fu">c</span>(omega_values<span class="sc">$</span>CI_high,<span class="cn">NA</span>)))</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="co"># append omega values to summary of anova table</span></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">summary</span>(mdl)[[<span class="dv">1</span>]],</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>      omega_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Df    Sum Sq    Mean Sq  F value        Pr(&gt;F) omega_sq omega_low
species       2 145190219 72595109.6 724.2080 3.079053e-121    0.813     0.781
sex           1  37090262 37090261.8 370.0121  8.729411e-56    0.526     0.457
Residuals   329  32979185   100240.7       NA            NA       NA        NA
            omega_high
species          0.838
sex              0.585
Residuals           NA</code></pre>
</div>
</div>
</section>
</section>
<section id="converting-between-effect-sizes-and-test-statistics" class="level2">
<h2 class="anchored" data-anchor-id="converting-between-effect-sizes-and-test-statistics">Converting between Effect Sizes and Test Statistics</h2>
<p>If raw data is unavailable and the necessary summary statistics are not reported, we can convert various statistics to effect size estimates. This section will focus on converting to three common effect sizes: Cohen’s <span class="math inline">\(d\)</span> values, Pearson correlations, and odds-ratios</p>
<section id="converting-to-cohens-d" class="level3">
<h3 class="anchored" data-anchor-id="converting-to-cohens-d">Converting to Cohen’s <span class="math inline">\(d\)</span></h3>
<section id="from-independent-samples-t-statistic" class="level4">
<h4 class="anchored" data-anchor-id="from-independent-samples-t-statistic">From Independent Samples <span class="math inline">\(t\)</span>-statistic</h4>
<p>To calculate a between subject standardized mean difference (<span class="math inline">\(d_p\)</span>, i.e., pooled standard deviation standardizer), we can use the sample size in each group (<span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>) as well as the <span class="math inline">\(t\)</span>-statistic from an independent sample t-test and plug it into the following formula:</p>
<p><span class="math display">\[
d_{p} = t\sqrt{\frac{1}{n_1}+\frac{1}{n_2} }
\]</span></p>
<p>Using the <code>t_to_d</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(t\)</span> to <span class="math inline">\(d_p\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># unpaired t-statistic = 3.25</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># n1 = 50, n2 = 40</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fl">3.25</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">40</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a><span class="fu">t_to_d</span>(t, <span class="at">df_error =</span> n1<span class="sc">+</span>n2<span class="dv">-2</span>, <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>d    |       95% CI
-------------------
0.69 | [0.26, 1.12]</code></pre>
</div>
</div>
</section>
<section id="from-paired-sample-t-statistic" class="level4">
<h4 class="anchored" data-anchor-id="from-paired-sample-t-statistic">From Paired Sample <span class="math inline">\(t\)</span>-statistic</h4>
<p>To calculate a within-subject standardized mean difference (<span class="math inline">\(d_z\)</span>, i.e., difference score standardizer), we can use the sample size in each group (<span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>) as well as the <span class="math inline">\(t\)</span>-statistic from an paired sample t-test and plug it into the following formula:</p>
<p><span class="math display">\[
d_{z} = \frac{t}{\sqrt{n}}
\]</span></p>
<p>Using the <code>t_to_d</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(t\)</span> to <span class="math inline">\(d_z\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># paired t-statistic = 3.25</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># n1 = 50, n2 = 40</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fl">3.25</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">40</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="fu">t_to_d</span>(t, <span class="at">df_error =</span> n1<span class="sc">+</span>n2<span class="dv">-2</span>, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>d    |       95% CI
-------------------
0.35 | [0.13, 0.56]</code></pre>
</div>
</div>
</section>
<section id="from-pearson-correlation" class="level4">
<h4 class="anchored" data-anchor-id="from-pearson-correlation">From Pearson Correlation</h4>
<p>If a Pearson correlation is calculated between a continuous score and a dichotomous score, this is considered a point-biserial correlation. The point-biserial correlation can be converted into a <span class="math inline">\(d_p\)</span> value using the following formula:</p>
<p><span class="math display">\[
d_p = \frac{r}{\sqrt{1-r^2}} \sqrt{\frac{n_1+n_2-2}{n_1} + \frac{n_1+n_2-2}{n_2}}
\]</span> Or if sample sizes within each group are unknown (or equal), the equatio simplifies to be approximately,</p>
<p><span class="math display">\[
d_p \approx \frac{r\sqrt{4}}{\sqrt{1-r^2}}
\]</span></p>
<p>Using the <code>r_to_d</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(r\)</span> to <span class="math inline">\(d_p\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="co"># r = 3.25</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># n1 = 50, n2 = 40</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> .<span class="dv">50</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">40</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="fu">r_to_d</span>(<span class="at">r =</span> r, <span class="at">n1 =</span> n1, <span class="at">n2 =</span> n2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.148913</code></pre>
</div>
</div>
</section>
<section id="from-odds-ratio" class="level4">
<h4 class="anchored" data-anchor-id="from-odds-ratio">From Odds-Ratio</h4>
<p>An odds-ratio from a contingency table can also be converted to a <span class="math inline">\(d_p\)</span>. Note that this formula is an approximation:</p>
<p><span class="math display">\[
d_{p} = \frac{\log(OR)\sqrt{3}}{\pi}
\]</span></p>
<p>Using the <code>oddsratio_to_d</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(OR\)</span> to <span class="math inline">\(d_p\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="co"># OR = 1.62</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>OR <span class="ot">&lt;-</span> <span class="fl">1.46</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="fu">oddsratio_to_d</span>(<span class="at">OR =</span> OR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2086429</code></pre>
</div>
</div>
</section>
</section>
<section id="converting-to-pearson-correlation" class="level3">
<h3 class="anchored" data-anchor-id="converting-to-pearson-correlation">Converting to Pearson Correlation</h3>
<section id="from-t-statistic" class="level4">
<h4 class="anchored" data-anchor-id="from-t-statistic">From <span class="math inline">\(t\)</span>-statistic</h4>
<p>From a <span class="math inline">\(t\)</span> statistic calculated from a correlational test, we can calculate the correlation coefficient using the following formula:</p>
<p><span class="math display">\[
r = \sqrt{\frac{t^2}{t^2 + n-2}}
\]</span></p>
<p>Using the <code>t_to_r</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(t\)</span> to <span class="math inline">\(r\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="co"># t = 4.14, n = 50</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fl">4.14</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="fu">t_to_r</span>(<span class="at">t =</span> t, <span class="at">df =</span> n<span class="dv">-2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>r    |       95% CI
-------------------
0.51 | [0.28, 0.67]</code></pre>
</div>
</div>
</section>
<section id="from-cohens-d" class="level4">
<h4 class="anchored" data-anchor-id="from-cohens-d">From Cohen’s <span class="math inline">\(d\)</span></h4>
<p>From a between groups Cohen’s <span class="math inline">\(d\)</span> value (<span class="math inline">\(d_p\)</span>), we can calculate the correlation coefficient from the following formula:</p>
<p><span class="math display">\[
r = \frac{d_p}{\sqrt{d_p^2+\frac{n_1+n_2-2}{n_1} + \frac{n_1+n_2-2}{n_2}}}
\]</span></p>
<p>Using the <code>d_to_r</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(d_p\)</span> to <span class="math inline">\(r\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co"># d = 0.60, n1 = 50, n2 = 70</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fl">0.60</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">70</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="fu">d_to_r</span>(<span class="at">d =</span> d, <span class="at">n1 =</span> n1, <span class="at">n2 =</span> n2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2858532</code></pre>
</div>
</div>
</section>
<section id="from-odds-ratio-1" class="level4">
<h4 class="anchored" data-anchor-id="from-odds-ratio-1">From Odds-Ratio</h4>
<p>The correlation coefficient from an odds ratio can be calculated with the following formula:</p>
<p><span class="math display">\[
r = \frac{\log(OR)\times\sqrt{3}}{\pi\sqrt{\frac{3\log(OR)^2}{\pi^2}+\frac{n_1+n_2-2}{n_1} + \frac{n_1+n_2-2}{n_2}}}
\]</span></p>
<p>Using the <code>oddsratio_to_r</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(OR\)</span> to <span class="math inline">\(r\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># OR = 2.21, n1 = 50, n2 = 70</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>OR <span class="ot">&lt;-</span> <span class="fl">2.21</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">70</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="fu">oddsratio_to_r</span>(<span class="at">OR=</span>OR, <span class="at">n1 =</span> n1, <span class="at">n2 =</span> n2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2124017</code></pre>
</div>
</div>
</section>
</section>
<section id="converting-to-odds-ratio" class="level3">
<h3 class="anchored" data-anchor-id="converting-to-odds-ratio">Converting to Odds-Ratio</h3>
<section id="from-cohens-d-1" class="level4">
<h4 class="anchored" data-anchor-id="from-cohens-d-1">From Cohen’s <span class="math inline">\(d\)</span></h4>
<p>We can calculate an odds-ratio from a between groups cohen’s <span class="math inline">\(d\)</span> (<span class="math inline">\(d_p\)</span>):</p>
<p><span class="math display">\[
OR = \exp\left(\frac{d_p \pi}{\sqrt{3}}\right)
\]</span></p>
<p>Where <span class="math inline">\(\exp(\cdot)\)</span> is an exponential transformation (this inverses the logarithm). Using the <code>d_to_oddsratio</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(d\)</span> to <span class="math inline">\(OR\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="co"># d = 0.60, n1 = 50, n2 = 70</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fl">0.60</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">70</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="fu">d_to_oddsratio</span>(<span class="at">d =</span> d, <span class="at">n1 =</span> n1, <span class="at">n2 =</span> n2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.969162</code></pre>
</div>
</div>
</section>
<section id="from-a-pearson-correlation" class="level4">
<h4 class="anchored" data-anchor-id="from-a-pearson-correlation">From a Pearson Correlation</h4>
<p>We can calculate an odds ratio from a Pearson correlation using the following formula:</p>
<p><span class="math display">\[
OR = \exp\left(\frac{r\pi \sqrt{\frac{n_1+n_2-2}{n_1} + \frac{n_1+n_2-2}{n_2}}}{\sqrt{3(1-r^2)}}\right)
\]</span></p>
<p>When sample sizes are equal, this equation can be simplified to be approximately,</p>
<p><span class="math display">\[
OR = \exp\left(\frac{r\pi \sqrt{4}}{\sqrt{3(1-r^2)}}\right)
\]</span></p>
<p>Using the <code>r_to_oddsratio</code> function in the <code>effectsize</code> package we can convert <span class="math inline">\(d\)</span> to <span class="math inline">\(OR\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="co"># r = .50, n1 = 50, n2 = 70</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> .<span class="dv">40</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="dv">70</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a><span class="fu">r_to_oddsratio</span>(<span class="at">r =</span> r, <span class="at">n1 =</span> n1, <span class="at">n2 =</span> n2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.870584</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="non-parametric-tests" class="level2">
<h2 class="anchored" data-anchor-id="non-parametric-tests">Non-Parametric Tests</h2>
<p>Sometimes the assumptions of parametric models (e.g., normality of model residuals) are suspect. This is often the case in psychology when using ordinal scales. In these cases a “non-parametric” approach may be helpful. A statistical test being non-parametric means that the parameters (i.e., mean and variance for “normal” Gaussian model) are not estimated; despite popular belief the data themselves are <em>never</em> non-parametric. Additionally, these tests are <em>not</em> tests of the median<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Rather one can consider than as rank based or proportional odds tests.</p>
<p>If the scores you are analyzing are not metric (i.e., ordinal) due to the use of a Likert-Scale and you still use parametric tests such as t-tests, you run the risk of a high false-positive probability (e.g., Liddel &amp; Kruschke, 2018). Note that in German, scale anchors have been developed that are very similar to Likert-Scale but can be interpreted as metric (e.g., Rohrmann, 1978).</p>
<p>We will briefly discuss here two groups of tests that can be applied to the independent and paired samples then present 3 effect sizes that can accompany these tests as well as their calculations and examples in R.</p>
<section id="wilcoxon-mann-whitney-tests" class="level3">
<h3 class="anchored" data-anchor-id="wilcoxon-mann-whitney-tests">Wilcoxon-Mann-Whitney tests</h3>
<p>A non-parametric alternative to the t-test is the Wilcoxon-Mann-Whitney (WMW) group of tests. When comparing two independent samples this is called a Wilcoxon rank-sum test, but sometimes to referred to as a Mann-Whitney U Test. When using it on paired samples, or one sample, it is a signed rank test. These are generally referred to as tests of “symmetry”<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired samples ---- </span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>library</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE, 
    logical.return = FALSE, warn.conflicts, quietly = FALSE, 
    verbose = getOption("verbose"), mask.ok, exclude, include.only, 
    attach.required = missing(include.only)) 
{
    if (!missing(package)) {
        package &lt;- package_name(enquo(package), character.only = character.only)
        conflicts_reset()
        on.exit(conflicts_register())
        on_detach(package, function() conflicts_remove(package))
        library(package, pos = pos, lib.loc = lib.loc, character.only = TRUE, 
            logical.return = logical.return, warn.conflicts = FALSE, 
            quietly = quietly, verbose = verbose, mask.ok = mask.ok, 
            exclude = exclude, include.only = include.only, attach.required = attach.required)
    }
    else if (!missing(help)) {
        help &lt;- package_name(enquo(help), character.only = character.only)
        library(help = help, character.only = TRUE)
    }
    else {
        library(lib.loc = lib.loc, logical.return = logical.return)
    }
}
&lt;bytecode: 0x112ad6c58&gt;
&lt;environment: namespace:conflicted&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(sleep)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="co"># wilcoxin test</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(extra <span class="sc">~</span> group,</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> sleep,</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Wilcoxon signed rank test with continuity correction

data:  extra by group
V = 0, p-value = 0.009091
alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Two Sample ------</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data import from likert</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mass, <span class="at">package =</span> <span class="st">"likert"</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>df_mass <span class="ot">=</span> mass <span class="sc">|&gt;</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">clean_names</span>() </span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a><span class="co"># function needs input as a numeric</span></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ordered factors can be converted to ranks</span></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Again, the warning can be ignored</span></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(<span class="fu">rank</span>(math_relates_to_my_life) <span class="sc">~</span> gender,</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> df_mass)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Wilcoxon rank sum test with continuity correction

data:  rank(math_relates_to_my_life) by gender
W = 23, p-value = 0.1104
alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
</div>
</section>
<section id="brunner-munzel-tests" class="level3">
<h3 class="anchored" data-anchor-id="brunner-munzel-tests">Brunner-Munzel Tests</h3>
<p>Brunner-Munzel’s tests can be used instead of the WMW tests. The primary reason is the interpretation of the test<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. The Brunner-Munzel tests measure a rank based “relative effect” or “stochastic superiority probability”. The test statistic (<span class="math inline">\(\hat p\)</span>) is essentially the probability of a value in one condition being greater than other while splitting the ties<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. However, Brunner-Munzel tests can not be applied to the single group or one-sample designs.</p>
<p><span class="math display">\[
\hat p = P(X&lt;Y)+ \frac{1}{2} \cdot P(X=Y)
\]</span></p>
<p>These tests are relatively new so there are very few packages offer Brunner-Munzel. However, the <code>TOSTER</code> R package does provide coverage.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install package for data cleaning</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages('janitor')</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(janitor)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired samples</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(sleep)</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Wilcoxin test</span></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(extra <span class="sc">~</span> group,</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> sleep,</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Wilcoxon signed rank test with continuity correction

data:  extra by group
V = 0, p-value = 0.009091
alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Two Sample</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data import from likert</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mass, <span class="at">package =</span> <span class="st">"likert"</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>df_mass <span class="ot">=</span> mass <span class="sc">|&gt;</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clean_names</span>() </span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="co"># function needs input as a numeric</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ordered factors can be converted to ranks</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="fu">wilcox.test</span>(<span class="fu">rank</span>(math_relates_to_my_life) <span class="sc">~</span> gender,</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> df_mass)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Wilcoxon rank sum test with continuity correction

data:  rank(math_relates_to_my_life) by gender
W = 23, p-value = 0.1104
alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
</div>
</section>
</section>
<section id="rank-based-effect-sizes" class="level2">
<h2 class="anchored" data-anchor-id="rank-based-effect-sizes">Rank-Based Effect Sizes</h2>
<p>Since the mean and standard deviation are not estimated for a WMW or Brunner-Munzel test, it would be inappropriate to present a standardized mean difference (e.g., Cohen’s d) to accompany these tests. Instead, a rank based effect size (i.e., based on the ranks of the observed values) can be reported to accompany the non-parametric statistical tests.</p>
<section id="rank-biserial-correlation" class="level3">
<h3 class="anchored" data-anchor-id="rank-biserial-correlation">Rank-Biserial Correlation</h3>
<p>The rank-biserial correlation (<span class="math inline">\(r_{rb}\)</span>) is considered a measure of dominance. The correlation represents the difference between the proportion of favorable and unfavorable pairs or signed ranks. Larger values indicate that more of X is larger than more of Y, with a value of (−1) indicates that all observations in the second, <span class="math inline">\(Y\)</span>, group are larger than the first, <span class="math inline">\(X\)</span>, group, and a value of (+1) indicates that all observations in the first group are larger than the second.</p>
<section id="paired-samples-calculation" class="level4">
<h4 class="anchored" data-anchor-id="paired-samples-calculation">Paired Samples Calculation</h4>
<ol type="1">
<li>Calculate difference scores between pairs:</li>
</ol>
<p><span class="math display">\[
D = X_2 - X_1
\]</span></p>
<ol start="2" type="1">
<li>Calculate the positive and negative rank sums:</li>
</ol>
<p><span class="math display">\[
\text{When } D_i&gt;0,\;\;  R_{\oplus} = \sum_{i=1} -1\cdot \text{sign}(D_i) \cdot \text{rank}(|D_i|)
\]</span></p>
<p><span class="math display">\[
\text{When } D_i&lt;0,\;\;  R_{\ominus} = \sum_{i=1} -1\cdot \text{sign}(D_i) \cdot \text{rank}(|D_i|)
\]</span></p>
<ol start="3" type="1">
<li>We can set a constant, <span class="math inline">\(H\)</span>, to be -1 when the rank positive rank sum is greater than or equal to the negative rank sum (<span class="math inline">\(R_{\oplus} \ge R_{\ominus}\)</span>) or we can set <span class="math inline">\(H\)</span> to 1 when the rank positive rank sum is less than the negative rank sum (<span class="math inline">\(R_{\oplus} &lt; R_{\ominus}\)</span>).</li>
</ol>
<p><span class="math display">\[
H = \begin{cases} -1 &amp;  R_{\oplus} \ge  R_{\ominus} \\ 1 &amp; R_{\oplus} &lt; R_{\ominus} \end{cases}
\]</span></p>
<ol start="4" type="1">
<li>Calculate rank-biserial correlation:</li>
</ol>
<p><span class="math display">\[
r_{rb} = 4H\times \left| \frac{\min( R_{\oplus}, R_{\ominus}) - .5\times ( R_{\oplus} +  R_{\ominus})}{n(n + 1)} \right|
\]</span></p>
<ol start="5" type="1">
<li>For paired samples, or one sample, the standard error is calculated as the following:</li>
</ol>
<p><span class="math display">\[
SE_{r_{rb}} = \sqrt{ \frac {(2 \cdot nd^3 + 3 \cdot nd^2 + nd) / 6} {(nd^2 + nd) / 2} }
\]</span> 6. The confidence intervals can then be calculated by Z-transforming the correlation.</p>
<p><span class="math display">\[
Z_{rb} = \text{arctanh}(r_{rb})
\]</span></p>
<ol start="7" type="1">
<li>Calculate the standard error of the Z-transformed correlation</li>
</ol>
<p><span class="math display">\[
SE_{Z_{rb}} = \frac{SE_{r_{rb}}}{1-r_{rb}^2}
\]</span></p>
<ol start="8" type="1">
<li>Then the confidence interval can be calculated and then back-transformed.</li>
</ol>
<p><span class="math display">\[
CI_{rb} = \text{tanh}(Z_{rb}  \pm  1.96 \cdot SE_{Z_{rb}})
\]</span></p>
</section>
<section id="two-sample-calculation" class="level4">
<h4 class="anchored" data-anchor-id="two-sample-calculation">Two Sample Calculation</h4>
<ol type="1">
<li>Calculate the ranks for each observation across all observations of in group 1 and 2</li>
</ol>
<p><span class="math display">\[
R = \text{rank}(X)
\]</span></p>
<ol start="2" type="1">
<li>Calculate the rank sums from each group</li>
</ol>
<p><span class="math display">\[
R_1 = \left(\sum_{i=1}^{n_1} R_1\right) - n_1 \cdot \frac{n_1 + 1}{2}
\]</span></p>
<p><span class="math display">\[
R_2 = \left(\sum_{i=1}^{n_2} R_2\right) - n_2 \cdot \frac{n_2 + 1}{2}
\]</span></p>
<ol start="3" type="1">
<li>Calculate the product of sample sizes</li>
</ol>
<p><span class="math display">\[
S = n_x \cdot n_y
\]</span></p>
<ol start="4" type="1">
<li>Calculate rank biserial correlation</li>
</ol>
<p><span class="math display">\[
r_{rb} = \frac{U_x}{S} - \frac{U_y}{S}
\]</span></p>
<ol start="5" type="1">
<li>For independent samples, the standard error is calculated as the following:</li>
</ol>
<p><span class="math display">\[
SE_{rb} = \sqrt{\frac {n_1 + n_2 + 1} { 3  n_1  n_2}}
\]</span></p>
<ol start="6" type="1">
<li>The confidence intervals can then be calculated by transforming the estimate.</li>
</ol>
<p><span class="math display">\[
Z_{rb} = \text{arctanh}(r_{rb})
\]</span></p>
<ol start="7" type="1">
<li>Calculate the standard error of the Z-transformed correlation</li>
</ol>
<p><span class="math display">\[
SE_{Z_{rb}} = \frac{SE_{r_{rb}}}{1-r_{rb}^2}
\]</span></p>
<ol start="8" type="1">
<li>Then the confidence interval can be calculated and then back-transformed.</li>
</ol>
<p><span class="math display">\[
CI_{rb} = \text{tanh}(Z_{rb}  \pm  1.96 \cdot SE_{Z_{rb}})
\]</span></p>
</section>
<section id="calculation-in-r" class="level4">
<h4 class="anchored" data-anchor-id="calculation-in-r">Calculation in R</h4>
<p>In R, we can use <code>brunner_munzel</code> in the <code>TOSTER</code> package can be utilized to calculate <span class="math inline">\(r_{rb}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired samples</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(sleep)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(TOSTER)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="co"># When sample sizes are small</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="co"># a permutation version should be used.</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="co"># When this is done a seed should be set.</span></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2124</span>)</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="fu">brunner_munzel</span>(extra <span class="sc">~</span> group,</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> sleep,</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">perm =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Paired Brunner-Munzel permutation test

data:  extra by group
t = -3.7266, df = 9, p-value = 0.003906
alternative hypothesis: true relative effect is not equal to 0.5
95 percent confidence interval:
 0.1233862 0.3866138
sample estimates:
p(X&lt;Y) + .5*P(X=Y) 
             0.255 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Two Sample</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data import from likert</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mass, <span class="at">package =</span> <span class="st">"likert"</span>)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>df_mass <span class="ot">=</span> mass <span class="sc">|&gt;</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clean_names</span>() </span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="co"># function needs input as a numeric</span></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ordered factors can be converted to ranks</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Again, the warning can be ignored</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">24111</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>TOSTER<span class="sc">::</span><span class="fu">brunner_munzel</span>(</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rank</span>(math_relates_to_my_life) <span class="sc">~</span> gender,</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_mass,</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">paired =</span> <span class="cn">FALSE</span>,</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">perm =</span> <span class="cn">TRUE</span></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    two-sample Brunner-Munzel permutation test

data:  rank(math_relates_to_my_life) by gender
t = -2.1665, df = 17.953, p-value = 0.0642
alternative hypothesis: true relative effect is not equal to 0.5
95 percent confidence interval:
 0.04761905 0.54961243
sample estimates:
p(X&lt;Y) + .5*P(X=Y) 
         0.2738095 </code></pre>
</div>
</div>
</section>
</section>
<section id="concordance-probability" class="level3">
<h3 class="anchored" data-anchor-id="concordance-probability">Concordance Probability</h3>
<p>In the two sample case, concordance probability is the probability that a randomly chosen subject from the one group has a response that is larger than that of a randomly chosen subject from the other group. In the two sample case, this is roughly equivalent to the statistic of the Brunner-Munzel test. In the paired sample case, it is the probability that a randomly chosen difference score (z) will have a positive (+) sign plus 0.5 times the probability of a tie (no/zero difference). The concordance probability can go by many names. It is also referred to as the c-index, the non-parametric probability of superiority, or the non-parametric common language effect size (CLES).</p>
<section id="calculation" class="level4">
<h4 class="anchored" data-anchor-id="calculation">Calculation</h4>
<p>The calculation of concordance can be derived from the rank-biserial correlation. The concordance probability (<span class="math inline">\(p_c\)</span>) can be converted from the correlation.</p>
<p><span class="math display">\[
p_c = \frac{r_{rb} + 1 }{2}
\]</span></p>
</section>
<section id="calculation-in-r-1" class="level4">
<h4 class="anchored" data-anchor-id="calculation-in-r-1">Calculation in R</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired samples</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(sleep)</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ses_calc</span>(extra <span class="sc">~</span> group,</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> sleep,</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">"c"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             estimate  lower.ci  upper.ci conf.level
Concordance 0.9909091 0.9641845 0.9977392       0.95</code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Two Sample</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data import from likert</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mass, <span class="at">package =</span> <span class="st">"likert"</span>)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>df_mass <span class="ot">=</span> mass <span class="sc">|&gt;</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">clean_names</span>()</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ses_calc</span>(<span class="fu">rank</span>(math_relates_to_my_life) <span class="sc">~</span> gender,</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> df_mass,</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">ses =</span> <span class="st">"c"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             estimate  lower.ci  upper.ci conf.level
Concordance 0.2738095 0.1084217 0.5389723       0.95</code></pre>
</div>
</div>
</section>
</section>
<section id="wilcoxin-mann-whitney-odds" class="level3">
<h3 class="anchored" data-anchor-id="wilcoxin-mann-whitney-odds">Wilcoxin-Mann-Whitney Odds</h3>
<p>The Wilcoxon-Mann-Whitney odds<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>, also known as the “Generalized Odds Ratio”<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, essentially transforms the concordance probability into an odds ratio.</p>
<section id="calculation-1" class="level4">
<h4 class="anchored" data-anchor-id="calculation-1">Calculation</h4>
<p>The odds can be converted from the concordance by taking the logit of the concordance. This will provide the log odds. The exponential value of the log-odds will provide the odds on a more interpretable scale.</p>
<p><span class="math display">\[
O_{WMW} = \exp \left[\text{logit}(p_c)\right]
\]</span></p>
<p><span class="math display">\[
\log(O_{WMW}) = \text{logit}(p_c)
\]</span></p>
</section>
<section id="calculation-in-r-2" class="level4">
<h4 class="anchored" data-anchor-id="calculation-in-r-2">Calculation in R</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired samples ----</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(sleep)</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>TOSTER<span class="sc">::</span><span class="fu">ses_calc</span>(extra <span class="sc">~</span> group,</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> sleep,</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">ses =</span> <span class="st">"odds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         estimate lower.ci upper.ci conf.level
WMW Odds      109 26.92087 441.3305       0.95</code></pre>
</div>
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Two Sample ------</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data import from likert</span></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mass, <span class="at">package =</span> <span class="st">"likert"</span>)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>df_mass <span class="ot">=</span> mass <span class="sc">|&gt;</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">clean_names</span>()</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>TOSTER<span class="sc">::</span><span class="fu">ses_calc</span>(  <span class="fu">rank</span>(math_relates_to_my_life) <span class="sc">~</span> gender,</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> df_mass,</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">ses =</span> <span class="st">"odds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          estimate  lower.ci upper.ci conf.level
WMW Odds 0.3770492 0.1216064 1.169067       0.95</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="artifacts-and-bias-in-effect-size-estimates" class="level2">
<h2 class="anchored" data-anchor-id="artifacts-and-bias-in-effect-size-estimates">Artifacts and Bias in Effect Size Estimates</h2>
<p>Effect size estimates such as correlation coefficients and Cohen’s <span class="math inline">\(d\)</span> values can be severely biased due to various statistical artifacts such as measurement error and selection effects (e.g., range restriction). Methods have been developed to correct for the bias in effect sizes and thus these corrections are called “artifact corrections”. Many artifact corrections can be complex and therefore readers are referred to other resources listed below:</p>
<ul>
<li><p><span class="citation" data-cites="MatthewBJane2023">Jané (<a href="#ref-MatthewBJane2023" role="doc-biblioref">2023</a>)</span> : An open-access textbook that contains equations and R code for various types of artifact corrections.</p></li>
<li><p><span class="citation" data-cites="hunter1990">Hunter and Schmidt (<a href="#ref-hunter1990" role="doc-biblioref">1990</a>)</span> : Classic textbook on the topic of artifact corrections. Hunter and Schmidt pioneered the methodology for artifact correction style meta-analyses.</p></li>
<li><p><span class="citation" data-cites="wiernik2020">Wiernik and Dahlke (<a href="#ref-wiernik2020" role="doc-biblioref">2020</a>)</span> : A paper that serves as a condensed version of Hunter and Schmidt’s book. It contains most of the equations necessary to correct effect sizes.</p></li>
<li><p><span class="citation" data-cites="psychmeta">Dahlke and Wiernik (<a href="#ref-psychmeta" role="doc-biblioref">2019</a>)</span> : An R package for conducting artifact correction meta-analyses. Contains all the functions one would need to correct effect sizes for artifacts in R.</p></li>
</ul>

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-association2010" class="csl-entry" role="listitem">
Association, American Psychological. 2010. <em>Publication Manual of the American Psychological Association</em>. American Psychological Association. <a href="https://thuvienso.hoasen.edu.vn/handle/123456789/8327">https://thuvienso.hoasen.edu.vn/handle/123456789/8327</a>.
</div>
<div id="ref-becker1988" class="csl-entry" role="listitem">
Becker, Betsy J. 1988. <span>“Synthesizing Standardized Mean-Change Measures - UConn Library.”</span> <em>British Journal of Mathematical and Statistical Psychology</em> 41 (2): 257278. https://doi.org/<a href="https://doi.org/10.1111/j.2044-8317.1988.tb00901.x">https://doi.org/10.1111/j.2044-8317.1988.tb00901.x</a>.
</div>
<div id="ref-effectsize" class="csl-entry" role="listitem">
Ben-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. <span>“<span class="nocase">e</span>ffectsize: Estimation of Effect Size Indices and Standardized Parameters.”</span> <em>Journal of Open Source Software</em> 5 (56): 2815. <a href="https://doi.org/10.21105/joss.02815">https://doi.org/10.21105/joss.02815</a>.
</div>
<div id="ref-benshachar2023" class="csl-entry" role="listitem">
Ben-Shachar, Mattan S., Indrajeet Patil, Rémi Thériault, Brenton M. Wiernik, and Daniel Lüdecke. 2023. <span>“Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the Chi-Squared Statistic.”</span> <em>Mathematics</em> 11 (9): 1982. <a href="https://doi.org/10.3390/math11091982">https://doi.org/10.3390/math11091982</a>.
</div>
<div id="ref-DeclareDesign" class="csl-entry" role="listitem">
Blair, Graeme, Jasper Cooper, Alexander Coppock, and Macartan Humphreys. 2019. <span>“Declaring and Diagnosing Research Designs.”</span> <em>American Political Science Review</em> 113: 838–59. <a href="https://declaredesign.org/paper.pdf">https://declaredesign.org/paper.pdf</a>.
</div>
<div id="ref-bosco2015" class="csl-entry" role="listitem">
Bosco, Frank A., Herman Aguinis, Kulraj Singh, James G. Field, and Charles A. Pierce. 2015. <span>“Correlational Effect Size Benchmarks.”</span> <em>Journal of Applied Psychology</em> 100 (2): 431–49. <a href="https://doi.org/10.1037/a0038047">https://doi.org/10.1037/a0038047</a>.
</div>
<div id="ref-MOTE" class="csl-entry" role="listitem">
Buchanan, Erin M., Amber Gillenwaters, John E. Scofield, and K. D. Valentine. 2019. <em><span class="nocase">MOTE: Measure of the Effect</span>: Package to Assist in Effect Size Calculations and Their Confidence Intervals</em>. <a href="http://github.com/doomlab/MOTE">http://github.com/doomlab/MOTE</a>.
</div>
<div id="ref-caldwell" class="csl-entry" role="listitem">
Caldwell, Aaron R. n.d. <span>“Exploring Equivalence Testing with the Updated TOSTER r Package.”</span> <a href="https://doi.org/10.31234/osf.io/ty8de">https://doi.org/10.31234/osf.io/ty8de</a>.
</div>
<div id="ref-coe2012" class="csl-entry" role="listitem">
Coe, R. 2012. <span>“It’s the Effect Size, Stupid What Effect Size Is and Why It Is Important.”</span> In. <a href="https://www.semanticscholar.org/paper/It%27s-the-Effect-Size%2C-Stupid-What-effect-size-is-it-Coe/c5ac87df5d6e0e6b6de2f745284835c2a368b0f7">https://www.semanticscholar.org/paper/It%27s-the-Effect-Size%2C-Stupid-What-effect-size-is-it-Coe/c5ac87df5d6e0e6b6de2f745284835c2a368b0f7</a>.
</div>
<div id="ref-cohen1988" class="csl-entry" role="listitem">
Cohen, Jacob. 1988. <em>Statistical Power Analysis for the Behavioral Sciences</em>. Academic Press.
</div>
<div id="ref-psychmeta" class="csl-entry" role="listitem">
Dahlke, Jeffrey A., and Brenton M. Wiernik. 2019. <span>“<span class="nocase">psychmeta</span>: An r Package for Psychometric Meta-Analysis.”</span> <em>Applied Psychological Measurement</em> 43 (5): 415–16. <a href="https://doi.org/10.1177/0146621618795933">https://doi.org/10.1177/0146621618795933</a>.
</div>
<div id="ref-TOSTER" class="csl-entry" role="listitem">
Daniel, Lakens, and aut. 2017. <span>“Equivalence Tests: A Practical Primer for t-Tests, Correlations, and Meta-Analyses.”</span> <em>Social Psychological and Personality Science</em> 1: 1–8. <a href="https://doi.org/10.1177/1948550617697177">https://doi.org/10.1177/1948550617697177</a>.
</div>
<div id="ref-faul2009" class="csl-entry" role="listitem">
Faul, Franz, Edgar Erdfelder, Axel Buchner, and Albert-Georg Lang. 2009. <span>“Statistical Power Analyses Using G*Power 3.1: Tests for Correlation and Regression Analyses.”</span> <em>Behavior Research Methods</em> 41 (4): 1149–60. <a href="https://doi.org/10.3758/BRM.41.4.1149">https://doi.org/10.3758/BRM.41.4.1149</a>.
</div>
<div id="ref-fritz2012" class="csl-entry" role="listitem">
Fritz, Catherine O., Peter E. Morris, and Jennifer J. Richler. 2012. <span>“Effect Size Estimates: Current Use, Calculations, and Interpretation.”</span> <em>Journal of Experimental Psychology: General</em> 141 (1): 2–18. <a href="https://doi.org/10.1037/a0024338">https://doi.org/10.1037/a0024338</a>.
</div>
<div id="ref-funder2019" class="csl-entry" role="listitem">
Funder, David C., and Daniel J. Ozer. 2019. <span>“Evaluating Effect Size in Psychological Research: Sense and Nonsense.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 2 (2): 156–68. <a href="https://doi.org/10.1177/2515245919847202">https://doi.org/10.1177/2515245919847202</a>.
</div>
<div id="ref-gignac2016" class="csl-entry" role="listitem">
Gignac, Gilles E., and Eva T. Szodorai. 2016. <span>“Effect Size Guidelines for Individual Differences Researchers.”</span> <em>Personality and Individual Differences</em> 102 (November): 74–78. <a href="https://doi.org/10.1016/j.paid.2016.06.069">https://doi.org/10.1016/j.paid.2016.06.069</a>.
</div>
<div id="ref-glass1981" class="csl-entry" role="listitem">
Glass, Gene V. 1981. <span>“Meta-Analysis in Social Research.”</span> <em>(No Title)</em>. <a href="https://cir.nii.ac.jp/crid/1130000795088566912">https://cir.nii.ac.jp/crid/1130000795088566912</a>.
</div>
<div id="ref-glass1981a" class="csl-entry" role="listitem">
Glass, Gene V., Barry McGaw, and Mary L. Smith. 1981. <span>“Meta-Analysis in Social Research.”</span> <em>(No Title)</em>. <a href="https://cir.nii.ac.jp/crid/1130000795088566912">https://cir.nii.ac.jp/crid/1130000795088566912</a>.
</div>
<div id="ref-harrell2020" class="csl-entry" role="listitem">
Harrell, Frank. 2020. <span>“Author Checklist - Data Analysis.”</span> <a href="https://discourse.datamethods.org/t/author-checklist/3407">https://discourse.datamethods.org/t/author-checklist/3407</a>.
</div>
<div id="ref-hedges1981" class="csl-entry" role="listitem">
Hedges, Larry V. 1981. <span>“Distribution Theory for Glass’s Estimator of Effect Size and Related Estimators.”</span> <em>Journal of Educational Statistics</em> 6 (2): 107–28. <a href="https://doi.org/10.3102/10769986006002107">https://doi.org/10.3102/10769986006002107</a>.
</div>
<div id="ref-hoekstra2014" class="csl-entry" role="listitem">
Hoekstra, Rink, Richard D. Morey, Jeffrey N. Rouder, and Eric-Jan Wagenmakers. 2014. <span>“Robust Misinterpretation of Confidence Intervals.”</span> <em>Psychonomic Bulletin &amp; Review</em> 21 (5): 1157–64. <a href="https://doi.org/10.3758/s13423-013-0572-3">https://doi.org/10.3758/s13423-013-0572-3</a>.
</div>
<div id="ref-hunter1990" class="csl-entry" role="listitem">
Hunter, John E., and Frank L. Schmidt. 1990. <em>Methods of meta-analysis: correcting error and bias in research findings</em>. Newbury Park: Sage Publications.
</div>
<div id="ref-MatthewBJane2023" class="csl-entry" role="listitem">
Jané, Matthew B. 2023. <em>Artifact Corrections for Effect Sizes: Implementation in r and Application to Meta-Analysis</em>. (n.p.). <a href="https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/">https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/</a>.
</div>
<div id="ref-MBESS" class="csl-entry" role="listitem">
Kelley, Ken. 2022. <em>MBESS: The MBESS r Package</em>. <a href="https://CRAN.R-project.org/package=MBESS">https://CRAN.R-project.org/package=MBESS</a>.
</div>
<div id="ref-kelley2012" class="csl-entry" role="listitem">
Kelley, Ken, and Kristopher J. Preacher. 2012. <span>“On Effect Size.”</span> <em>Psychological Methods</em> 17 (2): 137–52. <a href="https://doi.org/10.1037/a0028086">https://doi.org/10.1037/a0028086</a>.
</div>
<div id="ref-BootES" class="csl-entry" role="listitem">
Kirby, Kris N, and Daniel Gerlanc. 2013. <span>“BootES: An r Package for Bootstrap Confidence Intervals on Effect Sizes.”</span> <em>Behavior Research Methods</em> 45: 905–27.
</div>
<div id="ref-lakens2013" class="csl-entry" role="listitem">
Lakens, Daniel. 2013. <span>“Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and ANOVAs.”</span> <em>Frontiers in Psychology</em> 4. <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863">https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863</a>.
</div>
<div id="ref-lakens2014" class="csl-entry" role="listitem">
———. 2014. <span>“The 20.”</span> <a href="http://daniellakens.blogspot.com/2014/06/calculating-confidence-intervals-for.html">http://daniellakens.blogspot.com/2014/06/calculating-confidence-intervals-for.html</a>.
</div>
<div id="ref-lovakov2021" class="csl-entry" role="listitem">
Lovakov, Andrey, and Elena R. Agadullina. 2021. <span>“Empirically Derived Guidelines for Effect Size Interpretation in Social Psychology.”</span> <em>European Journal of Social Psychology</em> 51 (3): 485–504. <a href="https://doi.org/10.1002/ejsp.2752">https://doi.org/10.1002/ejsp.2752</a>.
</div>
<div id="ref-esc" class="csl-entry" role="listitem">
Lüdecke, Daniel. 2019. <em>Esc: Effect Size Computation for Meta Analysis (Version 0.5.1)</em>. <a href="https://doi.org/10.5281/zenodo.1249218">https://doi.org/10.5281/zenodo.1249218</a>.
</div>
<div id="ref-meehl1984" class="csl-entry" role="listitem">
Meehl, Paul E. 1984. <span>“Radical Behaviorism and Mental Events: Four Methodological Queries.”</span> <em>Behavioral and Brain Sciences</em> 7 (4): 563–64. <a href="https://doi.org/10.1017/S0140525X00027308">https://doi.org/10.1017/S0140525X00027308</a>.
</div>
<div id="ref-morey2016" class="csl-entry" role="listitem">
Morey, Richard D., Rink Hoekstra, Jeffrey N. Rouder, Michael D. Lee, and Eric-Jan Wagenmakers. 2016. <span>“The Fallacy of Placing Confidence in Confidence Intervals.”</span> <em>Psychonomic Bulletin &amp; Review</em> 23 (1): 103–23. <a href="https://doi.org/10.3758/s13423-015-0947-8">https://doi.org/10.3758/s13423-015-0947-8</a>.
</div>
<div id="ref-olkin1995" class="csl-entry" role="listitem">
Olkin, Ingram, and Jeremy D. Finn. 1995. <span>“Correlations Redux.”</span> <em>Psychological Bulletin</em> 118 (1): 155–64. <a href="https://doi.org/10.1037/0033-2909.118.1.155">https://doi.org/10.1037/0033-2909.118.1.155</a>.
</div>
<div id="ref-orben2020" class="csl-entry" role="listitem">
Orben, Amy, and Daniël Lakens. 2020. <span>“Crud (Re)Defined.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 3 (2): 238–47. <a href="https://doi.org/10.1177/2515245920917961">https://doi.org/10.1177/2515245920917961</a>.
</div>
<div id="ref-paterson2016" class="csl-entry" role="listitem">
Paterson, Ted A., P. D. Harms, Piers Steel, and Marcus Credé. 2016. <span>“An Assessment of the Magnitude of Effect Sizes: Evidence From 30 Years of Meta-Analysis in Management.”</span> <em>Journal of Leadership &amp; Organizational Studies</em> 23 (1): 66–81. <a href="https://doi.org/10.1177/1548051815614321">https://doi.org/10.1177/1548051815614321</a>.
</div>
<div id="ref-ufs" class="csl-entry" role="listitem">
Peters, Gjalt-Jorn Ygram, and Stefan Gruijters. 2023. <em>Ufs: A Collection of Utilities</em>. <a href="https://ufs.opens.science">https://ufs.opens.science</a>.
</div>
<div id="ref-pogrow2019" class="csl-entry" role="listitem">
Pogrow, Stanley. 2019. <span>“How Effect Size (Practical Significance) Misleads Clinical Practice: The Case for Switching to Practical Benefit to Assess Applied Research Findings.”</span> <em>The American Statistician</em> 73 (sup1): 223–34. <a href="https://doi.org/10.1080/00031305.2018.1549101">https://doi.org/10.1080/00031305.2018.1549101</a>.
</div>
<div id="ref-richard2003" class="csl-entry" role="listitem">
Richard, F. D., Charles F. Bond Jr., and Juli J. Stokes-Zoota. 2003. <span>“One Hundred Years of Social Psychology Quantitatively Described.”</span> <em>Review of General Psychology</em> 7 (4): 331–63. <a href="https://doi.org/10.1037/1089-2680.7.4.331">https://doi.org/10.1037/1089-2680.7.4.331</a>.
</div>
<div id="ref-sawilowsky2009" class="csl-entry" role="listitem">
Sawilowsky, Shlomo. 2009. <span>“New Effect Size Rules of Thumb.”</span> <em>Journal of Modern Applied Statistical Methods</em> 8 (2). <a href="https://doi.org/10.22237/jmasm/1257035100">https://doi.org/10.22237/jmasm/1257035100</a>.
</div>
<div id="ref-schäfer2019" class="csl-entry" role="listitem">
Schäfer, Thomas, and Marcus A. Schwarz. 2019. <span>“The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases.”</span> <em>Frontiers in Psychology</em> 10. <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813">https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813</a>.
</div>
<div id="ref-steiger2004" class="csl-entry" role="listitem">
Steiger, James H. 2004. <span>“Beyond the f Test: Effect Size Confidence Intervals and Tests of Close Fit in the Analysis of Variance and Contrast Analysis.”</span> <em>Psychological Methods</em> 9 (2): 164–82. <a href="https://doi.org/10.1037/1082-989X.9.2.164">https://doi.org/10.1037/1082-989X.9.2.164</a>.
</div>
<div id="ref-effsize" class="csl-entry" role="listitem">
Torchiano, Marco. 2020. <em>Effsize: Efficient Effect Size Computation</em>. <a href="https://doi.org/10.5281/zenodo.1480624">https://doi.org/10.5281/zenodo.1480624</a>.
</div>
<div id="ref-metafor" class="csl-entry" role="listitem">
Viechtbauer, Wolfgang. 2010. <span>“Conducting Meta-Analyses in <span>R</span> with the <span class="nocase">metafor</span> Package.”</span> <em>Journal of Statistical Software</em> 36 (3): 1–48. <a href="https://doi.org/10.18637/jss.v036.i03">https://doi.org/10.18637/jss.v036.i03</a>.
</div>
<div id="ref-vos2022" class="csl-entry" role="listitem">
Vos, Paul, and Don Holbert. 2022. <span>“Frequentist Statistical Inference Without Repeated Sampling.”</span> <em>Synthese</em> 200 (2): 89. <a href="https://doi.org/10.1007/s11229-022-03560-x">https://doi.org/10.1007/s11229-022-03560-x</a>.
</div>
<div id="ref-MAd" class="csl-entry" role="listitem">
W. T. Hoyt, A. C. Del Re &amp;. 2014. <em>MAd: Meta-Analysis with Mean Differences</em>. <em>R Package</em>. <a href="https://CRAN.R-project.org/package=MAd">https://CRAN.R-project.org/package=MAd</a>.
</div>
<div id="ref-wiernik2020" class="csl-entry" role="listitem">
Wiernik, Brenton M., and Jeffrey A. Dahlke. 2020. <span>“Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 3 (1): 94–123. <a href="https://doi.org/10.1177/2515245919885611">https://doi.org/10.1177/2515245919885611</a>.
</div>
<div id="ref-psych" class="csl-entry" role="listitem">
William Revelle. 2023. <em>Psych: Procedures for Psychological, Psychometric, and Personality Research</em>. Evanston, Illinois: Northwestern University. <a href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Divine, G. W., Norton, H. J., Barón, A. E., &amp; Juarez-Colunga, E. (2018). The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians. The American Statistician (Vol. 72, Issue 3, pp.&nbsp;278–286). https://doi.org/10.1080/00031305.2017.1305291<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="citation" data-cites="sawilowsky2009">Sawilowsky (<a href="#ref-sawilowsky2009" role="doc-biblioref">2009</a>)</span> expanded Cohen’s benchmarks to include also very small effects (<span class="math inline">\(d\)</span> = 0.01), very large effects (<span class="math inline">\(d\)</span> = 1.20), and huge effects (<span class="math inline">\(d\)</span> = 2.0). It has to be noted that very large and huge effects are very rare in experimental social psychology.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>1) Brunner, E., Munzel, U. (2000). The Nonparametric Behrens-Fisher Problem: Asymptotic Theory and a Small Sample Approximation. Biometrical Journal 42, 17 -25. 2) 2) Neubert, K., Brunner, E., (2006). A Studentized Permutation Test for the Nonparametric Behrens-Fisher Problem. Computational Statistics and Data Analysis. 3) Munzel, U., Brunner, E. (2002). An Exact Paired Rank Test. Biometrical Journal 44, 584-593.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Note, for paired samples, this does not refer to the probability of an increase/decrease in paired sample but rather the probability that a randomly sampled value of X. This is also referred to as the “relative” effect in the literature. Therefore, the results will differ from the concordance probability provided below.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>These benchmarks are also recommended by <span class="citation" data-cites="gignac2016">Gignac and Szodorai (<a href="#ref-gignac2016" role="doc-biblioref">2016</a>)</span>. <span class="citation" data-cites="funder2019">Funder and Ozer (<a href="#ref-funder2019" role="doc-biblioref">2019</a>)</span> expanded them to also include very small effects (<span class="math inline">\(r\)</span> = .05) and very large effects (<span class="math inline">\(r\)</span> = .40 or greater). According to them, […] an effect-size r of .05 indicates an effect that is very small for the explanation of single events but potentially consequential in the not-very-long run, an effect-size r of .10 indicates an effect that is still small at the level of single events but potentially more ultimately consequential, an effect-size <span class="math inline">\(r\)</span> of .20 indicates a medium effect that is of some explanatory and practical use even in the short run and therefore even more important, and an effect-size <span class="math inline">\(r\)</span> of .30 indicates a large effect that is potentially powerful in both the short and the long run. A very large effect size (r = .40 or greater) in the context of psychological research is likely to be a gross overestimate that will rarely be found in a large sample or in a replication.” But see <a href="https://twitter.com/aaronjfisher/status/1168252264600883200?s=20">here</a> for controversies with this paper.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>The benchmarks for Cramer’s V are dependent on the size of the contingency table on which the effect is calculated. According to Cohen, use benchmarks for phi coefficient divided by the square root of the smaller dimension minus 1. For example, a medium effect for a Cramer’s V from a 4 by 3 table would be .3 / sqrt(3 - 1) = .21.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Of course, if a theory/effect predicts Group X has a higher mean than Group Y, then it also predicts the reverse, i.e., Group Y has a lower mean than Group X. But theories/effects are commonly articulated in a certain way. It is more common that we say, for example, people prefer the status quo rather than that people do not prefer the non-status quo, when we refer to the status quo bias. Consider another “theory”: teenagers get taller when they get older. It just does not make sense to say the same thing reversely, i.e., teenagers get shorter when they get younger, because people cannot get younger, at least in the 2020s.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Divine, G. W., Norton, H. J., Barón, A. E., &amp; Juarez-Colunga, E. (2018). The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians. The American Statistician (Vol. 72, Issue 3, pp.&nbsp;278–286). https://doi.org/10.1080/00031305.2017.1305291<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Divine, G. W., Norton, H. J., Barón, A. E., &amp; Juarez-Colunga, E. (2018). The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians. The American Statistician (Vol. 72, Issue 3, pp.&nbsp;278–286). https://doi.org/10.1080/00031305.2017.1305291<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>1) Brunner, E., Munzel, U. (2000). The Nonparametric Behrens-Fisher Problem: Asymptotic Theory and a Small Sample Approximation. Biometrical Journal 42, 17 -25. 2) 2) Neubert, K., Brunner, E., (2006). A Studentized Permutation Test for the Nonparametric Behrens-Fisher Problem. Computational Statistics and Data Analysis. 3) Munzel, U., Brunner, E. (2002). An Exact Paired Rank Test. Biometrical Journal 44, 584-593.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Note, for paired samples, this does not refer to the probability of an increase/decrease in paired sample but rather the probability that a randomly sampled value of X. This is also referred to as the “relative” effect in the literature. Therefore, the results will differ from the concordance probability provided below.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>O’Brien, Ralph G, and John Castelloe. 2006. “Exploiting the Link Between the Wilcoxon-Mann-Whitney Test and a Simple Odds Statistic,” 209–31.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Agresti, Alan. 1980. “Generalized Odds Ratios for Ordinal Data.” Biometrics, 59–67. https://doi.org/10.2307/2530495. <a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>